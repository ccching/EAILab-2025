{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KRm0_WztAPe"
   },
   "source": [
    "# 2025 EAI Lab 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2e7m9tHTpR0H"
   },
   "source": [
    "## Topic 1 : From PyTorch To ONNX\n",
    "\n",
    "### Steps:\n",
    "1.   Define Model Architecture\n",
    "2.   Load Weight\n",
    "3.   Export ONNX File\n",
    "4.   Quantize To INT8\n",
    "5.   Building Session\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "vt7LM45spK0Q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/ccching/miniconda3/lib/python3.13/site-packages (2.9.0)\n",
      "Collecting torch\n",
      "  Using cached torch-2.9.1-cp313-cp313-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: torchvision in /home/ccching/miniconda3/lib/python3.13/site-packages (0.24.0)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.24.1-cp313-cp313-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
      "Collecting torchaudio\n",
      "  Using cached torchaudio-2.9.1-cp313-cp313-manylinux_2_28_x86_64.whl.metadata (6.9 kB)\n",
      "Collecting onnx\n",
      "  Using cached onnx-1.20.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
      "Collecting onnxscript\n",
      "  Using cached onnxscript-0.5.6-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting onnxruntime\n",
      "  Using cached onnxruntime-1.23.2-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
      "Collecting onnxruntime-tools\n",
      "  Using cached onnxruntime_tools-1.7.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting onnxruntime-gpu\n",
      "  Using cached onnxruntime_gpu-1.23.2-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting gradio\n",
      "  Using cached gradio-6.0.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: filelock in /home/ccching/miniconda3/lib/python3.13/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/ccching/miniconda3/lib/python3.13/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /home/ccching/miniconda3/lib/python3.13/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/ccching/miniconda3/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/ccching/miniconda3/lib/python3.13/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/ccching/miniconda3/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /home/ccching/miniconda3/lib/python3.13/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/ccching/miniconda3/lib/python3.13/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/ccching/miniconda3/lib/python3.13/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/ccching/miniconda3/lib/python3.13/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/ccching/miniconda3/lib/python3.13/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/ccching/miniconda3/lib/python3.13/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/ccching/miniconda3/lib/python3.13/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/ccching/miniconda3/lib/python3.13/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/ccching/miniconda3/lib/python3.13/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/ccching/miniconda3/lib/python3.13/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/ccching/miniconda3/lib/python3.13/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/ccching/miniconda3/lib/python3.13/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/ccching/miniconda3/lib/python3.13/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/ccching/miniconda3/lib/python3.13/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/ccching/miniconda3/lib/python3.13/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/ccching/miniconda3/lib/python3.13/site-packages (from torch) (1.13.1.3)\n",
      "Collecting triton==3.5.1 (from torch)\n",
      "  Using cached triton-3.5.1-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: numpy in /home/ccching/miniconda3/lib/python3.13/site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ccching/miniconda3/lib/python3.13/site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: protobuf>=4.25.1 in /home/ccching/miniconda3/lib/python3.13/site-packages (from onnx) (6.33.1)\n",
      "Collecting ml_dtypes>=0.5.0 (from onnx)\n",
      "  Using cached ml_dtypes-0.5.4-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Collecting onnx_ir<2,>=0.1.12 (from onnxscript)\n",
      "  Using cached onnx_ir-0.1.12-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: packaging in /home/ccching/miniconda3/lib/python3.13/site-packages (from onnxscript) (25.0)\n",
      "Collecting coloredlogs (from onnxruntime)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime)\n",
      "  Using cached flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: psutil in /home/ccching/miniconda3/lib/python3.13/site-packages (from onnxruntime-tools) (7.1.2)\n",
      "Collecting py-cpuinfo (from onnxruntime-tools)\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting py3nvml (from onnxruntime-tools)\n",
      "  Using cached py3nvml-0.2.7-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
      "  Using cached aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /home/ccching/miniconda3/lib/python3.13/site-packages (from gradio) (4.10.0)\n",
      "Collecting audioop-lts<1.0 (from gradio)\n",
      "  Using cached audioop_lts-0.2.2-cp313-abi3-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting brotli>=1.1.0 (from gradio)\n",
      "  Using cached brotli-1.2.0-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Using cached fastapi-0.124.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Using cached ffmpy-1.0.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting gradio-client==2.0.1 (from gradio)\n",
      "  Using cached gradio_client-2.0.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy~=0.1 (from gradio)\n",
      "  Using cached groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in /home/ccching/miniconda3/lib/python3.13/site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /home/ccching/miniconda3/lib/python3.13/site-packages (from gradio) (0.36.0)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /home/ccching/miniconda3/lib/python3.13/site-packages (from gradio) (3.0.2)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Using cached orjson-3.11.5-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /home/ccching/miniconda3/lib/python3.13/site-packages (from gradio) (2.2.3)\n",
      "Collecting pydantic<=2.12.4,>=2.11.10 (from gradio)\n",
      "  Using cached pydantic-2.12.4-py3-none-any.whl.metadata (89 kB)\n",
      "Collecting pydub (from gradio)\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /home/ccching/miniconda3/lib/python3.13/site-packages (from gradio) (6.0.3)\n",
      "Collecting safehttpx<0.2.0,>=0.1.7 (from gradio)\n",
      "  Using cached safehttpx-0.1.7-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Using cached starlette-0.50.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Using cached tomlkit-0.13.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Using cached typer-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Using cached uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ccching/miniconda3/lib/python3.13/site-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ccching/miniconda3/lib/python3.13/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Collecting annotated-doc>=0.0.2 (from fastapi<1.0,>=0.115.2->gradio)\n",
      "  Using cached annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: certifi in /home/ccching/miniconda3/lib/python3.13/site-packages (from httpx<1.0,>=0.24.1->gradio) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ccching/miniconda3/lib/python3.13/site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ccching/miniconda3/lib/python3.13/site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
      "Requirement already satisfied: requests in /home/ccching/miniconda3/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ccching/miniconda3/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/ccching/miniconda3/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ccching/miniconda3/lib/python3.13/site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ccching/miniconda3/lib/python3.13/site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ccching/miniconda3/lib/python3.13/site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ccching/miniconda3/lib/python3.13/site-packages (from pydantic<=2.12.4,>=2.11.10->gradio) (0.6.0)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<=2.12.4,>=2.11.10->gradio)\n",
      "  Using cached pydantic_core-2.41.5-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<=2.12.4,>=2.11.10->gradio)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/ccching/miniconda3/lib/python3.13/site-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/ccching/miniconda3/lib/python3.13/site-packages (from typer<1.0,>=0.12->gradio) (1.5.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/ccching/miniconda3/lib/python3.13/site-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/ccching/miniconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ccching/miniconda3/lib/python3.13/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ccching/miniconda3/lib/python3.13/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ccching/miniconda3/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ccching/miniconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting xmltodict (from py3nvml->onnxruntime-tools)\n",
      "  Using cached xmltodict-1.0.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ccching/miniconda3/lib/python3.13/site-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ccching/miniconda3/lib/python3.13/site-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
      "Downloading torch-2.9.1-cp313-cp313-manylinux_2_28_x86_64.whl (899.7 MB)\n",
      "\u001b[2K   \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.0/899.7 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:18\u001b[0m\u001b[31mERROR: Could not install packages due to an OSError: [Errno 28] No space left on device\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[2K   \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.5/899.7 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:18\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -U \\\n",
    "    torch torchvision torchaudio \\\n",
    "    onnx onnxscript onnxruntime onnxruntime-tools onnxruntime-gpu \\\n",
    "    gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MCKZlTEIqkOD"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# TODO\n",
    "# Design Your ResNet18 Model\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.left = nn.Sequential(\n",
    "                    nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "                    nn.BatchNorm2d(out_channels),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                    nn.BatchNorm2d(out_channels)\n",
    "                )\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.left(x)\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self,num_classes=10):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.layer1 = self._make_layer(BasicBlock, 64, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(BasicBlock, 128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(BasicBlock, 256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(BasicBlock, 512, 2, stride=2)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for s in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, s))\n",
    "            self.in_channels = out_channels \n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        \n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        \n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        \n",
    "        out = out.view(out.size(0), -1) \n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "RUErZRINpUU5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from best_model.pth...\n",
      "Weights loaded successfully.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'onnxscript'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 51\u001b[39m\n\u001b[32m     47\u001b[39m   \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     50\u001b[39m   \u001b[38;5;66;03m# 提醒 : 記得先把 best_model.pth 上傳到 Content 資料夾\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m   \u001b[43mexport_onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbest_model.pth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mexport_onnx\u001b[39m\u001b[34m(model, dummy, path)\u001b[39m\n\u001b[32m     36\u001b[39m model.eval()\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Todo : Export ONNX FILE\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43monnx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdummy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mNM6131051_FP32.onnx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m11\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/onnx/__init__.py:282\u001b[39m, in \u001b[36mexport\u001b[39m\u001b[34m(model, args, f, kwargs, verbose, input_names, output_names, opset_version, dynamo, external_data, dynamic_shapes, custom_translation_table, report, optimize, verify, profile, dump_exported_program, artifacts_dir, fallback, export_params, keep_initializers_as_inputs, dynamic_axes, training, operator_export_type, do_constant_folding, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Exports a model into ONNX format.\u001b[39;00m\n\u001b[32m    100\u001b[39m \n\u001b[32m    101\u001b[39m \u001b[33;03mSetting ``dynamo=True`` enables the new ONNX export logic\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    279\u001b[39m \u001b[33;03m    *dynamo* is now True by default.\u001b[39;00m\n\u001b[32m    280\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dynamo \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, torch.export.ExportedProgram):\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01monnx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_internal\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexporter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _compat\n\u001b[32m    284\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args, torch.Tensor):\n\u001b[32m    285\u001b[39m         args = (args,)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/onnx/_internal/exporter/_compat.py:16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01monnx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _constants \u001b[38;5;28;01mas\u001b[39;00m onnx_constants\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01monnx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_internal\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_lazy_import\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m onnx, onnxscript_apis, onnxscript_ir \u001b[38;5;28;01mas\u001b[39;00m ir\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01monnx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_internal\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexporter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     17\u001b[39m     _constants,\n\u001b[32m     18\u001b[39m     _core,\n\u001b[32m     19\u001b[39m     _dynamic_shapes,\n\u001b[32m     20\u001b[39m     _onnx_program,\n\u001b[32m     21\u001b[39m     _registration,\n\u001b[32m     22\u001b[39m )\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/onnx/_internal/exporter/_core.py:18\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollections\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mabc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Mapping, Sequence\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Literal\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01monnxscript\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01monnxscript\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevaluator\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01monnxscript\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ir\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'onnxscript'"
     ]
    }
   ],
   "source": [
    "torch_model = ResNet18(num_classes=10)\n",
    "dummy_input = (torch.randn(1, 3, 32, 32),)\n",
    "\n",
    "def export_onnx(model, dummy, path):\n",
    "  print(f\"Loading weights from {path}...\")\n",
    "  try:\n",
    "      state = torch.load(path, map_location=torch.device(\"cpu\"))\n",
    "\n",
    "      # 1. 如果存檔時包了一層 'state_dict'，先取出來\n",
    "      if 'state_dict' in state:\n",
    "          state = state['state_dict']\n",
    "\n",
    "      # 2. 清洗 State Dict (移除 module. 前綴 與 多餘的統計 key)\n",
    "      new_state_dict = {}\n",
    "      for k, v in state.items():\n",
    "          # 移除 DataParallel 可能產生的 'module.' 前綴\n",
    "          name = k.replace(\"module.\", \"\")\n",
    "          \n",
    "          # 【關鍵修改】過濾掉包含 total_ops 或 total_params 的 key\n",
    "          if \"total_ops\" in name or \"total_params\" in name:\n",
    "              continue\n",
    "              \n",
    "          new_state_dict[name] = v\n",
    "\n",
    "      # 3. 載入清洗後的權重\n",
    "      # strict=True (預設) 會確保權重完全對應，現在清洗乾淨了應該不會報錯\n",
    "      model.load_state_dict(new_state_dict)\n",
    "      print(\"Weights loaded successfully.\")\n",
    "\n",
    "  except Exception as e:\n",
    "      print(f\"Error loading weights: {e}\")\n",
    "      # 如果還是報錯，可以嘗試把下面這行取消註解，強制忽略錯誤（不推薦，除非真的找不到原因）\n",
    "      # model.load_state_dict(new_state_dict, strict=False) \n",
    "      return\n",
    "\n",
    "  model.eval()\n",
    "\n",
    "  # Todo : Export ONNX FILE\n",
    "  torch.onnx.export(\n",
    "      model,\n",
    "      dummy,\n",
    "      \"NM6131051_FP32.onnx\",\n",
    "      input_names=[\"input\"],\n",
    "      output_names=[\"output\"],\n",
    "      opset_version=11,\n",
    "  )\n",
    "  pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  # 提醒 : 記得先把 best_model.pth 上傳到 Content 資料夾\n",
    "  export_onnx(model=torch_model, dummy=dummy_input, path=\"best_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PnBfgSxfpUzD"
   },
   "outputs": [],
   "source": [
    "import os, numpy as np\n",
    "from PIL import Image\n",
    "import onnxruntime as ort\n",
    "from onnxruntime.quantization import CalibrationDataReader\n",
    "\n",
    "CIFAR10_MEAN = np.array([0.4914, 0.4822, 0.4465], dtype=np.float32)\n",
    "CIFAR10_STD  = np.array([0.2470, 0.2435, 0.2616], dtype=np.float32)\n",
    "\n",
    "def preprocess_32x32(pil_img: Image.Image) -> np.ndarray:\n",
    "    arr = np.asarray(pil_img.convert(\"RGB\").resize((32, 32)), dtype=np.float32) / 255.0\n",
    "    arr = (arr - CIFAR10_MEAN) / CIFAR10_STD\n",
    "    return arr.transpose(2, 0, 1)[None, ...]  # (1,3,32,32)\n",
    "\n",
    "class CIFARLikeCalibReader(CalibrationDataReader):\n",
    "    def __init__(self, image_dir: str = None, input_name: str = \"input\",\n",
    "                 batch_size: int = 32, num_batches: int = 10):\n",
    "        self.input_name  = input_name\n",
    "        self.batch_size  = batch_size\n",
    "        self.num_batches = num_batches\n",
    "        self.paths = []\n",
    "        if image_dir and os.path.isdir(image_dir):\n",
    "            for f in os.listdir(image_dir):\n",
    "                if f.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\")):\n",
    "                    self.paths.append(os.path.join(image_dir, f))\n",
    "        self._mode_random = len(self.paths) == 0\n",
    "        self._pos = 0\n",
    "        self._emitted = 0\n",
    "\n",
    "    def get_next(self):\n",
    "        if self._emitted >= self.num_batches:\n",
    "            return None\n",
    "        if self._mode_random:\n",
    "            batch = np.random.randn(self.batch_size, 3, 32, 32).astype(np.float32)\n",
    "        else:\n",
    "            items = []\n",
    "            for _ in range(self.batch_size):\n",
    "                if self._pos >= len(self.paths):\n",
    "                    break\n",
    "                img = Image.open(self.paths[self._pos])\n",
    "                self._pos += 1\n",
    "                items.append(preprocess_32x32(img))\n",
    "            if not items:\n",
    "                return None\n",
    "            batch = np.concatenate(items, axis=0).astype(np.float32)\n",
    "        self._emitted += 1\n",
    "        return {self.input_name: batch}\n",
    "\n",
    "    def rewind(self):\n",
    "        self._pos = 0\n",
    "        self._emitted = 0\n",
    "\n",
    "FP32_MODEL = \"image_classifier_model.onnx\"\n",
    "INT8_MODEL = \"image_classifier_model_int8.onnx\"\n",
    "\n",
    "\n",
    "_tmp = ort.InferenceSession(FP32_MODEL, providers=[\"CPUExecutionProvider\"])\n",
    "INPUT_NAME = _tmp.get_inputs()[0].name\n",
    "print(\"Calib will use input name:\", INPUT_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9_HL4D23phIN"
   },
   "outputs": [],
   "source": [
    "from onnxruntime.quantization import quantize_static, QuantType, CalibrationMethod\n",
    "\n",
    "\n",
    "\n",
    "reader = CIFARLikeCalibReader(\n",
    "    image_dir=None,\n",
    "    input_name=INPUT_NAME,\n",
    "    batch_size=1,\n",
    "    num_batches=50\n",
    ")\n",
    "\n",
    "\n",
    "def quantize_to_int8(fp32_path, int8_path, reader, method=\"MinMax\"):\n",
    "    # Todo : quantize_static\n",
    "    quantize_static(\n",
    "\n",
    "    )\n",
    "    print(\"Saved INT8 model:\", INT8_MODEL)\n",
    "\n",
    "quantize_to_int8(FP32_MODEL, INT8_MODEL, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VYZIE2Rdpj3G"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "\n",
    "def run(sess, x):\n",
    "    return sess.run(None, {sess.get_inputs()[0].name: x})[0]\n",
    "\n",
    "x_demo = np.random.randn(1,3,32,32).astype(np.float32)\n",
    "\n",
    "# Todo : build session function\n",
    "def build_session(model_path, providers):\n",
    "  return\n",
    "\n",
    "\n",
    "\n",
    "sess_fp32 = build_session(model_path=FP32_MODEL, providers=[\"CPUExecutionProvider\"])\n",
    "sess_int8 = build_session(model_path=INT8_MODEL, providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "y_fp32 = run(sess_fp32, x_demo)\n",
    "y_int8 = run(sess_int8, x_demo)\n",
    "\n",
    "l2_rel = np.linalg.norm(y_fp32 - y_int8) / (np.linalg.norm(y_fp32) + 1e-12)\n",
    "print(f\"[Check] relative L2 diff FP32 vs INT8: {l2_rel:.6f}\")\n",
    "\n",
    "def bench(sess, x, n=50):\n",
    "    t0 = time.time()\n",
    "    for _ in range(n):\n",
    "        sess.run(None, {sess.get_inputs()[0].name: x})\n",
    "    return (time.time() - t0) / n\n",
    "\n",
    "print(\"FP32 avg sec:\", bench(sess_fp32, x_demo))\n",
    "print(\"INT8 avg sec:\", bench(sess_int8, x_demo))\n",
    "\n",
    "so = ort.SessionOptions()\n",
    "so.enable_profiling = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OeFccLG1pehx"
   },
   "source": [
    "## Topic 2 : Gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qFNo0K7gvJqd"
   },
   "outputs": [],
   "source": [
    "! pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_vE9Tel_tI76"
   },
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "import time\n",
    "\n",
    "# ====== Config ======\n",
    "MODEL_PATH_INT8 = \"image_classifier_model_int8.onnx\"   # INT8 ONNX Model\n",
    "MODEL_PATH_FP32 = \"image_classifier_model.onnx\"     # FP32 ONNX Model\n",
    "LABELS = ['plane','car','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "\n",
    "# CIFAR-10 Normalization Parameter\n",
    "CIFAR10_MEAN = np.array([0.4914, 0.4822, 0.4465], dtype=np.float32)\n",
    "CIFAR10_STD  = np.array([0.2470, 0.2435, 0.2616], dtype=np.float32)\n",
    "\n",
    "# ====== Utils ======\n",
    "def softmax_np(x: np.ndarray) -> np.ndarray:\n",
    "    x = x - np.max(x)\n",
    "    ex = np.exp(x)\n",
    "    return ex / np.sum(ex)\n",
    "\n",
    "# TODO : preprocess input image function\n",
    "def preprocess(image: Image.Image) -> np.ndarray:\n",
    "    \"\"\"輸入 PIL Image → (1,3,32,32) float32\"\"\"\n",
    "    if not isinstance(image, Image.Image):\n",
    "        raise ValueError(\"Plese Upload Image\")\n",
    "\n",
    "\n",
    "    return arr\n",
    "\n",
    "# ====== ONNX Sessions ======\n",
    "providers = ort.get_available_providers()\n",
    "\n",
    "sess_int8 = build_session(MODEL_PATH_INT8, providers=providers)\n",
    "in_int8  = sess_int8.get_inputs()[0].name\n",
    "out_int8 = sess_int8.get_outputs()[0].name\n",
    "\n",
    "\n",
    "try:\n",
    "    sess_fp32 = build_session(MODEL_PATH_FP32, providers=providers)\n",
    "    in_fp32  = sess_fp32.get_inputs()[0].name\n",
    "    out_fp32 = sess_fp32.get_outputs()[0].name\n",
    "    _fp32_err = \"\"\n",
    "except Exception as e:\n",
    "    sess_fp32, in_fp32, out_fp32 = None, None, None\n",
    "    _fp32_err = f\"[FP32 load failure] {type(e).__name__}: {e}\"\n",
    "\n",
    "# ====== Compare FP32 and INT8 ======\n",
    "# TODO : Compare FP32 and INT8\n",
    "def compare_fp32_int8(image: Image.Image):\n",
    "    if image is None:\n",
    "        return {}, {}, \"Please Upload Your Image。\"\n",
    "    if sess_fp32 is None:\n",
    "        return {}, {}, (_fp32_err or \"The FP32 model has not been provided, so a comparison cannot be made.\")\n",
    "\n",
    "    x = preprocess(image)\n",
    "\n",
    "    # Your progarm\n",
    "\n",
    "\n",
    "    p_fp32 = softmax_np()\n",
    "    p_int8 = softmax_np()\n",
    "\n",
    "    def top3_map(p):\n",
    "        idx = np.argpartition(p, -3)[-3:]\n",
    "        idx = idx[np.argsort(p[idx])[::-1]]\n",
    "        return {LABELS[i]: float(p[i]) for i in idx}\n",
    "\n",
    "    top3_fp32 = top3_map(p_fp32)\n",
    "    top3_int8 = top3_map(p_int8)\n",
    "\n",
    "    summary = (\n",
    "        f\"FP32 inference time: {fp32_ms:.2f} ms\\n\"\n",
    "        f\"INT8 inference time: {int8_ms:.2f} ms\\n\"\n",
    "        f\"Speedup (FP32/INT8): {(fp32_ms / max(int8_ms, 1e-9)):.2f}×\"\n",
    "    )\n",
    "    return top3_fp32, top3_int8, summary\n",
    "\n",
    "# ====== Gradio UI ======\n",
    "# TODO : Building GUI Interface\n",
    "demo = gr.Interface(\n",
    "    fn = compare_fp32_int8,\n",
    "    inputs =\n",
    "    outputs =\n",
    "    title =\n",
    "    description =\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  # TODO : building a public web\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOV/rmsswwtq7Dm7IE3hnwD",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgVOunpmwdT5"
      },
      "source": [
        "# Knowledge Distillation\n",
        "- The concept of **knowledge distillation** is to utilize class probabilities of a higher-capacity model (teacher) as soft targets of a smaller model (student)\n",
        "- The implement processes can be divided into several stages:\n",
        "  1. Finish the `ResNet()` classes\n",
        "  2. Train the teacher model (ResNet50) and the student model (ResNet18) from scratch, i.e. **without KD**\n",
        "  3. Define the `Distiller()` class and `loss_re()`, `loss_fe()` functions\n",
        "  4. Train the student model **with KD** from the teacher model in two different ways, response-based and feature based distillation\n",
        "  5. Comparison of student models w/ & w/o KD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w40lLxA3wdT7"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:20:41.614280Z",
          "iopub.status.busy": "2025-09-15T17:20:41.614011Z",
          "iopub.status.idle": "2025-09-15T17:20:46.740522Z",
          "shell.execute_reply": "2025-09-15T17:20:46.739828Z",
          "shell.execute_reply.started": "2025-09-15T17:20:41.614239Z"
        },
        "id": "xAYyvlYlwdT8",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchinfo in /home/ccching/miniconda3/lib/python3.13/site-packages (1.8.0)\n"
          ]
        }
      ],
      "source": [
        "# ! pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-09-15T17:20:46.742442Z",
          "iopub.status.busy": "2025-09-15T17:20:46.742139Z",
          "iopub.status.idle": "2025-09-15T17:20:56.618435Z",
          "shell.execute_reply": "2025-09-15T17:20:56.617889Z",
          "shell.execute_reply.started": "2025-09-15T17:20:46.742411Z"
        },
        "id": "NivvmktxwdT9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms, models\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchinfo import summary\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:20:56.619518Z",
          "iopub.status.busy": "2025-09-15T17:20:56.619135Z",
          "iopub.status.idle": "2025-09-15T17:20:56.709343Z",
          "shell.execute_reply": "2025-09-15T17:20:56.708758Z",
          "shell.execute_reply.started": "2025-09-15T17:20:56.619491Z"
        },
        "id": "3n9ohVimwdT9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npQT5vdwwdT9"
      },
      "source": [
        "## Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:20:56.711171Z",
          "iopub.status.busy": "2025-09-15T17:20:56.710947Z",
          "iopub.status.idle": "2025-09-15T17:21:02.244060Z",
          "shell.execute_reply": "2025-09-15T17:21:02.243410Z",
          "shell.execute_reply.started": "2025-09-15T17:20:56.711154Z"
        },
        "id": "4WprgXfzwdT9",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:12<00:00, 13.2MB/s] \n"
          ]
        }
      ],
      "source": [
        "validation_split = 0.2\n",
        "batch_size = 128\n",
        "\n",
        "# data augmentation and normalization\n",
        "transform_train = transforms.Compose([\n",
        "                    transforms.RandomCrop(32, padding=4),\n",
        "                    transforms.RandomHorizontalFlip(),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# download dataset\n",
        "train_and_val_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='dataset/',\n",
        "    train=True,\n",
        "    transform=transform_train,\n",
        "    download=True\n",
        ")\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='dataset/',\n",
        "    train=False,\n",
        "    transform=transform_test,\n",
        "    download=True\n",
        ")\n",
        "\n",
        "# split train and validation dataset\n",
        "train_size = int((1 - validation_split) * len(train_and_val_dataset))\n",
        "val_size = len(train_and_val_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(train_and_val_dataset, [train_size, val_size])\n",
        "\n",
        "# create dataLoader\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "test_num = len(test_dataset)\n",
        "test_steps = len(test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dz3sXl-pwdT9"
      },
      "source": [
        "## Create teacher and student models\n",
        "### Define BottleNeck for ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:21:02.245043Z",
          "iopub.status.busy": "2025-09-15T17:21:02.244775Z",
          "iopub.status.idle": "2025-09-15T17:21:02.252293Z",
          "shell.execute_reply": "2025-09-15T17:21:02.251546Z",
          "shell.execute_reply.started": "2025-09-15T17:21:02.245018Z"
        },
        "id": "xNQHKkcVwdT9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class BottleNeck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_channel, out_channel, stride=1, downsample=None, **kwargs):\n",
        "        super(BottleNeck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=1, stride=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
        "        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
        "        self.conv3 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel * self.expansion, kernel_size=1, stride=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channel * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIZdxOh-wdT-"
      },
      "source": [
        "### Define Resifual Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:21:02.253296Z",
          "iopub.status.busy": "2025-09-15T17:21:02.253067Z",
          "iopub.status.idle": "2025-09-15T17:21:02.277396Z",
          "shell.execute_reply": "2025-09-15T17:21:02.276882Z",
          "shell.execute_reply.started": "2025-09-15T17:21:02.253273Z"
        },
        "id": "wkJimDp7wdT-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channel, out_channel, stride=1, downsample=None, **kwargs):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKwQR8oKwdT-"
      },
      "source": [
        "### Define ResNet Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:21:02.278332Z",
          "iopub.status.busy": "2025-09-15T17:21:02.278077Z",
          "iopub.status.idle": "2025-09-15T17:21:02.301112Z",
          "shell.execute_reply": "2025-09-15T17:21:02.300587Z",
          "shell.execute_reply.started": "2025-09-15T17:21:02.278307Z"
        },
        "id": "neQ5KljZwdT-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, blocks_num, num_classes=1000):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channel = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, self.in_channel, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_channel)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, blocks_num[0])\n",
        "        self.layer2 = self._make_layer(block, 128, blocks_num[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, blocks_num[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, blocks_num[3], stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "\n",
        "    def _make_layer(self, block, channel, block_num, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.in_channel != channel * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channel, channel * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(channel * block.expansion))\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channel, channel, downsample=downsample, stride=stride))\n",
        "        self.in_channel = channel * block.expansion\n",
        "\n",
        "        for _ in range(1, block_num):\n",
        "            layers.append(block(self.in_channel, channel))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 1. Finish the forward pass and return the output layer as well as hidden features.\n",
        "        # 2. The output layer and hidden features will be used later for distilling.\n",
        "        # 3. You can refer to the ResNet structure illustration to finish it.\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        #layer output\n",
        "        feature1 = self.layer1(x)\n",
        "        feature2 = self.layer2(feature1)\n",
        "        feature3 = self.layer3(feature2)\n",
        "        feature4 = self.layer4(feature3)\n",
        "\n",
        "        out = self.avgpool(feature4)\n",
        "        out = torch.flatten(out, 1)\n",
        "        x = self.fc(out)\n",
        "        return x, [feature1, feature2, feature3, feature4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOy4lBgSwdT-"
      },
      "source": [
        "### Define ResNet50 and Resnet18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:21:02.302108Z",
          "iopub.status.busy": "2025-09-15T17:21:02.301868Z",
          "iopub.status.idle": "2025-09-15T17:21:02.321736Z",
          "shell.execute_reply": "2025-09-15T17:21:02.321258Z",
          "shell.execute_reply.started": "2025-09-15T17:21:02.302092Z"
        },
        "id": "WmkTpoYzwdT-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def resnet18(num_classes=10):\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n",
        "\n",
        "def resnet50(num_classes=10):\n",
        "    return ResNet(BottleNeck, [3, 4, 6, 3], num_classes=num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vzi6uxFwdT-"
      },
      "source": [
        "## Teacher Model (ResNet50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:21:02.322519Z",
          "iopub.status.busy": "2025-09-15T17:21:02.322350Z",
          "iopub.status.idle": "2025-09-15T17:21:04.197301Z",
          "shell.execute_reply": "2025-09-15T17:21:04.196547Z",
          "shell.execute_reply.started": "2025-09-15T17:21:02.322505Z"
        },
        "id": "1UaF4WGXwdT-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "Teacher = resnet50(num_classes=10)  # commment out this line if loading trained teacher model\n",
        "# Teacher = torch.load('Teacher.pt', weights_only=False)  # loading trained teacher model\n",
        "Teacher = Teacher.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dmwXM_WtwdT_",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "ResNet                                   --\n",
              "├─Conv2d: 1-1                            1,728\n",
              "├─BatchNorm2d: 1-2                       128\n",
              "├─ReLU: 1-3                              --\n",
              "├─MaxPool2d: 1-4                         --\n",
              "├─Sequential: 1-5                        --\n",
              "│    └─BottleNeck: 2-1                   --\n",
              "│    │    └─Conv2d: 3-1                  4,096\n",
              "│    │    └─BatchNorm2d: 3-2             128\n",
              "│    │    └─Conv2d: 3-3                  36,864\n",
              "│    │    └─BatchNorm2d: 3-4             128\n",
              "│    │    └─Conv2d: 3-5                  16,384\n",
              "│    │    └─BatchNorm2d: 3-6             512\n",
              "│    │    └─ReLU: 3-7                    --\n",
              "│    │    └─Sequential: 3-8              16,896\n",
              "│    └─BottleNeck: 2-2                   --\n",
              "│    │    └─Conv2d: 3-9                  16,384\n",
              "│    │    └─BatchNorm2d: 3-10            128\n",
              "│    │    └─Conv2d: 3-11                 36,864\n",
              "│    │    └─BatchNorm2d: 3-12            128\n",
              "│    │    └─Conv2d: 3-13                 16,384\n",
              "│    │    └─BatchNorm2d: 3-14            512\n",
              "│    │    └─ReLU: 3-15                   --\n",
              "│    └─BottleNeck: 2-3                   --\n",
              "│    │    └─Conv2d: 3-16                 16,384\n",
              "│    │    └─BatchNorm2d: 3-17            128\n",
              "│    │    └─Conv2d: 3-18                 36,864\n",
              "│    │    └─BatchNorm2d: 3-19            128\n",
              "│    │    └─Conv2d: 3-20                 16,384\n",
              "│    │    └─BatchNorm2d: 3-21            512\n",
              "│    │    └─ReLU: 3-22                   --\n",
              "├─Sequential: 1-6                        --\n",
              "│    └─BottleNeck: 2-4                   --\n",
              "│    │    └─Conv2d: 3-23                 32,768\n",
              "│    │    └─BatchNorm2d: 3-24            256\n",
              "│    │    └─Conv2d: 3-25                 147,456\n",
              "│    │    └─BatchNorm2d: 3-26            256\n",
              "│    │    └─Conv2d: 3-27                 65,536\n",
              "│    │    └─BatchNorm2d: 3-28            1,024\n",
              "│    │    └─ReLU: 3-29                   --\n",
              "│    │    └─Sequential: 3-30             132,096\n",
              "│    └─BottleNeck: 2-5                   --\n",
              "│    │    └─Conv2d: 3-31                 65,536\n",
              "│    │    └─BatchNorm2d: 3-32            256\n",
              "│    │    └─Conv2d: 3-33                 147,456\n",
              "│    │    └─BatchNorm2d: 3-34            256\n",
              "│    │    └─Conv2d: 3-35                 65,536\n",
              "│    │    └─BatchNorm2d: 3-36            1,024\n",
              "│    │    └─ReLU: 3-37                   --\n",
              "│    └─BottleNeck: 2-6                   --\n",
              "│    │    └─Conv2d: 3-38                 65,536\n",
              "│    │    └─BatchNorm2d: 3-39            256\n",
              "│    │    └─Conv2d: 3-40                 147,456\n",
              "│    │    └─BatchNorm2d: 3-41            256\n",
              "│    │    └─Conv2d: 3-42                 65,536\n",
              "│    │    └─BatchNorm2d: 3-43            1,024\n",
              "│    │    └─ReLU: 3-44                   --\n",
              "│    └─BottleNeck: 2-7                   --\n",
              "│    │    └─Conv2d: 3-45                 65,536\n",
              "│    │    └─BatchNorm2d: 3-46            256\n",
              "│    │    └─Conv2d: 3-47                 147,456\n",
              "│    │    └─BatchNorm2d: 3-48            256\n",
              "│    │    └─Conv2d: 3-49                 65,536\n",
              "│    │    └─BatchNorm2d: 3-50            1,024\n",
              "│    │    └─ReLU: 3-51                   --\n",
              "├─Sequential: 1-7                        --\n",
              "│    └─BottleNeck: 2-8                   --\n",
              "│    │    └─Conv2d: 3-52                 131,072\n",
              "│    │    └─BatchNorm2d: 3-53            512\n",
              "│    │    └─Conv2d: 3-54                 589,824\n",
              "│    │    └─BatchNorm2d: 3-55            512\n",
              "│    │    └─Conv2d: 3-56                 262,144\n",
              "│    │    └─BatchNorm2d: 3-57            2,048\n",
              "│    │    └─ReLU: 3-58                   --\n",
              "│    │    └─Sequential: 3-59             526,336\n",
              "│    └─BottleNeck: 2-9                   --\n",
              "│    │    └─Conv2d: 3-60                 262,144\n",
              "│    │    └─BatchNorm2d: 3-61            512\n",
              "│    │    └─Conv2d: 3-62                 589,824\n",
              "│    │    └─BatchNorm2d: 3-63            512\n",
              "│    │    └─Conv2d: 3-64                 262,144\n",
              "│    │    └─BatchNorm2d: 3-65            2,048\n",
              "│    │    └─ReLU: 3-66                   --\n",
              "│    └─BottleNeck: 2-10                  --\n",
              "│    │    └─Conv2d: 3-67                 262,144\n",
              "│    │    └─BatchNorm2d: 3-68            512\n",
              "│    │    └─Conv2d: 3-69                 589,824\n",
              "│    │    └─BatchNorm2d: 3-70            512\n",
              "│    │    └─Conv2d: 3-71                 262,144\n",
              "│    │    └─BatchNorm2d: 3-72            2,048\n",
              "│    │    └─ReLU: 3-73                   --\n",
              "│    └─BottleNeck: 2-11                  --\n",
              "│    │    └─Conv2d: 3-74                 262,144\n",
              "│    │    └─BatchNorm2d: 3-75            512\n",
              "│    │    └─Conv2d: 3-76                 589,824\n",
              "│    │    └─BatchNorm2d: 3-77            512\n",
              "│    │    └─Conv2d: 3-78                 262,144\n",
              "│    │    └─BatchNorm2d: 3-79            2,048\n",
              "│    │    └─ReLU: 3-80                   --\n",
              "│    └─BottleNeck: 2-12                  --\n",
              "│    │    └─Conv2d: 3-81                 262,144\n",
              "│    │    └─BatchNorm2d: 3-82            512\n",
              "│    │    └─Conv2d: 3-83                 589,824\n",
              "│    │    └─BatchNorm2d: 3-84            512\n",
              "│    │    └─Conv2d: 3-85                 262,144\n",
              "│    │    └─BatchNorm2d: 3-86            2,048\n",
              "│    │    └─ReLU: 3-87                   --\n",
              "│    └─BottleNeck: 2-13                  --\n",
              "│    │    └─Conv2d: 3-88                 262,144\n",
              "│    │    └─BatchNorm2d: 3-89            512\n",
              "│    │    └─Conv2d: 3-90                 589,824\n",
              "│    │    └─BatchNorm2d: 3-91            512\n",
              "│    │    └─Conv2d: 3-92                 262,144\n",
              "│    │    └─BatchNorm2d: 3-93            2,048\n",
              "│    │    └─ReLU: 3-94                   --\n",
              "├─Sequential: 1-8                        --\n",
              "│    └─BottleNeck: 2-14                  --\n",
              "│    │    └─Conv2d: 3-95                 524,288\n",
              "│    │    └─BatchNorm2d: 3-96            1,024\n",
              "│    │    └─Conv2d: 3-97                 2,359,296\n",
              "│    │    └─BatchNorm2d: 3-98            1,024\n",
              "│    │    └─Conv2d: 3-99                 1,048,576\n",
              "│    │    └─BatchNorm2d: 3-100           4,096\n",
              "│    │    └─ReLU: 3-101                  --\n",
              "│    │    └─Sequential: 3-102            2,101,248\n",
              "│    └─BottleNeck: 2-15                  --\n",
              "│    │    └─Conv2d: 3-103                1,048,576\n",
              "│    │    └─BatchNorm2d: 3-104           1,024\n",
              "│    │    └─Conv2d: 3-105                2,359,296\n",
              "│    │    └─BatchNorm2d: 3-106           1,024\n",
              "│    │    └─Conv2d: 3-107                1,048,576\n",
              "│    │    └─BatchNorm2d: 3-108           4,096\n",
              "│    │    └─ReLU: 3-109                  --\n",
              "│    └─BottleNeck: 2-16                  --\n",
              "│    │    └─Conv2d: 3-110                1,048,576\n",
              "│    │    └─BatchNorm2d: 3-111           1,024\n",
              "│    │    └─Conv2d: 3-112                2,359,296\n",
              "│    │    └─BatchNorm2d: 3-113           1,024\n",
              "│    │    └─Conv2d: 3-114                1,048,576\n",
              "│    │    └─BatchNorm2d: 3-115           4,096\n",
              "│    │    └─ReLU: 3-116                  --\n",
              "├─AdaptiveAvgPool2d: 1-9                 --\n",
              "├─Linear: 1-10                           20,490\n",
              "=================================================================\n",
              "Total params: 23,520,842\n",
              "Trainable params: 23,520,842\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary(Teacher)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZ4wlBakwdT_"
      },
      "source": [
        "## Student Model (ResNet18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:21:04.213935Z",
          "iopub.status.busy": "2025-09-15T17:21:04.213631Z",
          "iopub.status.idle": "2025-09-15T17:21:04.400068Z",
          "shell.execute_reply": "2025-09-15T17:21:04.399483Z",
          "shell.execute_reply.started": "2025-09-15T17:21:04.213911Z"
        },
        "id": "QsBS9LxPwdT_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "Student = resnet18(num_classes=10)  # commment out this line if loading trained student model\n",
        "# Student = torch.load('Student.pt', weights_only=False)  # loading trained student model\n",
        "Student = Student.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OJ8nTtDswdT_",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "ResNet                                   --\n",
              "├─Conv2d: 1-1                            1,728\n",
              "├─BatchNorm2d: 1-2                       128\n",
              "├─ReLU: 1-3                              --\n",
              "├─MaxPool2d: 1-4                         --\n",
              "├─Sequential: 1-5                        --\n",
              "│    └─BasicBlock: 2-1                   --\n",
              "│    │    └─Conv2d: 3-1                  36,864\n",
              "│    │    └─BatchNorm2d: 3-2             128\n",
              "│    │    └─ReLU: 3-3                    --\n",
              "│    │    └─Conv2d: 3-4                  36,864\n",
              "│    │    └─BatchNorm2d: 3-5             128\n",
              "│    └─BasicBlock: 2-2                   --\n",
              "│    │    └─Conv2d: 3-6                  36,864\n",
              "│    │    └─BatchNorm2d: 3-7             128\n",
              "│    │    └─ReLU: 3-8                    --\n",
              "│    │    └─Conv2d: 3-9                  36,864\n",
              "│    │    └─BatchNorm2d: 3-10            128\n",
              "├─Sequential: 1-6                        --\n",
              "│    └─BasicBlock: 2-3                   --\n",
              "│    │    └─Conv2d: 3-11                 73,728\n",
              "│    │    └─BatchNorm2d: 3-12            256\n",
              "│    │    └─ReLU: 3-13                   --\n",
              "│    │    └─Conv2d: 3-14                 147,456\n",
              "│    │    └─BatchNorm2d: 3-15            256\n",
              "│    │    └─Sequential: 3-16             8,448\n",
              "│    └─BasicBlock: 2-4                   --\n",
              "│    │    └─Conv2d: 3-17                 147,456\n",
              "│    │    └─BatchNorm2d: 3-18            256\n",
              "│    │    └─ReLU: 3-19                   --\n",
              "│    │    └─Conv2d: 3-20                 147,456\n",
              "│    │    └─BatchNorm2d: 3-21            256\n",
              "├─Sequential: 1-7                        --\n",
              "│    └─BasicBlock: 2-5                   --\n",
              "│    │    └─Conv2d: 3-22                 294,912\n",
              "│    │    └─BatchNorm2d: 3-23            512\n",
              "│    │    └─ReLU: 3-24                   --\n",
              "│    │    └─Conv2d: 3-25                 589,824\n",
              "│    │    └─BatchNorm2d: 3-26            512\n",
              "│    │    └─Sequential: 3-27             33,280\n",
              "│    └─BasicBlock: 2-6                   --\n",
              "│    │    └─Conv2d: 3-28                 589,824\n",
              "│    │    └─BatchNorm2d: 3-29            512\n",
              "│    │    └─ReLU: 3-30                   --\n",
              "│    │    └─Conv2d: 3-31                 589,824\n",
              "│    │    └─BatchNorm2d: 3-32            512\n",
              "├─Sequential: 1-8                        --\n",
              "│    └─BasicBlock: 2-7                   --\n",
              "│    │    └─Conv2d: 3-33                 1,179,648\n",
              "│    │    └─BatchNorm2d: 3-34            1,024\n",
              "│    │    └─ReLU: 3-35                   --\n",
              "│    │    └─Conv2d: 3-36                 2,359,296\n",
              "│    │    └─BatchNorm2d: 3-37            1,024\n",
              "│    │    └─Sequential: 3-38             132,096\n",
              "│    └─BasicBlock: 2-8                   --\n",
              "│    │    └─Conv2d: 3-39                 2,359,296\n",
              "│    │    └─BatchNorm2d: 3-40            1,024\n",
              "│    │    └─ReLU: 3-41                   --\n",
              "│    │    └─Conv2d: 3-42                 2,359,296\n",
              "│    │    └─BatchNorm2d: 3-43            1,024\n",
              "├─AdaptiveAvgPool2d: 1-9                 --\n",
              "├─Linear: 1-10                           5,130\n",
              "=================================================================\n",
              "Total params: 11,173,962\n",
              "Trainable params: 11,173,962\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary(Student)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qF1RPSfrwdT_"
      },
      "source": [
        "## Define training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:21:04.411876Z",
          "iopub.status.busy": "2025-09-15T17:21:04.411049Z",
          "iopub.status.idle": "2025-09-15T17:21:04.429748Z",
          "shell.execute_reply": "2025-09-15T17:21:04.429207Z",
          "shell.execute_reply.started": "2025-09-15T17:21:04.411856Z"
        },
        "id": "sYihMy4lwdT_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def train_from_scratch(model, train_loader, val_loader, epochs, learning_rate, device, model_name):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = torch.optim.Adam(params, lr=learning_rate)\n",
        "\n",
        "    loss = []\n",
        "    train_error=[]\n",
        "    val_error = []\n",
        "    valdation_error = []\n",
        "    train_loss = []\n",
        "    valdation_loss = []\n",
        "    train_accuraacy = []\n",
        "    valdation_accuracy= []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        train_acc = 0.0\n",
        "        valid_acc = 0.0\n",
        "        correct = 0.\n",
        "        total = 0.\n",
        "        V_correct = 0.\n",
        "        V_total = 0.\n",
        "\n",
        "        model.train()\n",
        "        train_bar = tqdm(train_loader, file=sys.stdout)\n",
        "        for step, data in enumerate(train_bar):\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits, hidden = model(images)\n",
        "            loss = criterion(logits, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * images.size(0)\n",
        "            pred = logits.data.max(1, keepdim=True)[1]\n",
        "            correct += np.sum(np.squeeze(pred.eq(labels.data.view_as(pred))).cpu().numpy())\n",
        "            total += images.size(0)\n",
        "            train_acc =  correct/total\n",
        "            train_bar.desc = \"train epoch[{}/{}]\".format(epoch + 1, epochs)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_bar = tqdm(val_loader, file=sys.stdout)\n",
        "            for val_data in val_bar:\n",
        "                val_images, val_labels = val_data\n",
        "                val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
        "                outputs, hidden_outputs = model(val_images)\n",
        "                loss = criterion(outputs, val_labels)\n",
        "                valid_loss += loss.item() * val_images.size(0)\n",
        "                pred = outputs.data.max(1, keepdim=True)[1]\n",
        "                V_correct += np.sum(np.squeeze(pred.eq(val_labels.data.view_as(pred))).cpu().numpy())\n",
        "                V_total += val_images.size(0)\n",
        "                val_bar.desc = \"valid epoch[{}/{}]\".format(epoch + 1, epochs)\n",
        "\n",
        "        train_loss = train_loss / len(train_loader.dataset)\n",
        "        train_error.append(train_loss)\n",
        "        valid_loss = valid_loss / len(val_loader.dataset)\n",
        "        val_error.append(valid_loss)\n",
        "        train_accuraacy.append( correct / total)\n",
        "        valdation_accuracy.append(V_correct / V_total)\n",
        "\n",
        "        print('\\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(train_loss, valid_loss))\n",
        "        print('\\tTrain Accuracy: %.3fd%% (%2d/%2d)\\tValdation Accuracy: %.3fd%% (%2d/%2d) '% (100. * correct / total, correct, total, 100. * V_correct / V_total, V_correct, V_total))\n",
        "\n",
        "    torch.save(model, f'{model_name}.pt')\n",
        "    print(f'{model_name}.pt is saved')\n",
        "\n",
        "    print('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJihXOROwdT_"
      },
      "source": [
        "## Define testing function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:21:04.431037Z",
          "iopub.status.busy": "2025-09-15T17:21:04.430762Z",
          "iopub.status.idle": "2025-09-15T17:21:04.452490Z",
          "shell.execute_reply": "2025-09-15T17:21:04.451992Z",
          "shell.execute_reply.started": "2025-09-15T17:21:04.431014Z"
        },
        "id": "IMcS6k_lwdT_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def test(model, test_loader ,device, type=None):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    acc = 0.0\n",
        "    test_loss = 0.0\n",
        "\n",
        "    if type == None:\n",
        "        model.eval()\n",
        "    elif type == 'distiller':\n",
        "        model.eval()\n",
        "        model.teacher.eval()\n",
        "        model.student.eval()\n",
        "    else:\n",
        "       raise ValueError(f'Error: only support response-based and feature-based distillation')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        test_bar = tqdm(test_loader, file=sys.stdout)\n",
        "        for test_data in test_bar:\n",
        "            test_images, test_labels = test_data\n",
        "            test_images, test_labels = test_images.to(device), test_labels.to(device)\n",
        "            if type == None:\n",
        "                outputs, features = model(test_images)\n",
        "                loss = criterion(outputs, test_labels)\n",
        "            elif type == 'distiller':\n",
        "                outputs, loss = model(test_images, test_labels)\n",
        "            else:\n",
        "                raise ValueError(f'Error: only support response-based and feature-based distillation')\n",
        "\n",
        "            predict_y = torch.max(outputs, dim=1)[1]\n",
        "            acc += torch.eq(predict_y, test_labels.to(device)).sum().item()\n",
        "            test_loss += loss.item()\n",
        "            test_bar.desc = \"test\"\n",
        "\n",
        "    test_accurate = acc / test_num\n",
        "    print('test_loss: %.3f  test_accuracy: %.3f' %(test_loss / test_steps, test_accurate * 100))\n",
        "    return test_loss / test_steps, test_accurate * 100."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOCKqaHXwdUA"
      },
      "source": [
        "## Train Teacher and Student model from scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:21:04.453428Z",
          "iopub.status.busy": "2025-09-15T17:21:04.453203Z",
          "iopub.status.idle": "2025-09-15T17:21:04.473303Z",
          "shell.execute_reply": "2025-09-15T17:21:04.472761Z",
          "shell.execute_reply.started": "2025-09-15T17:21:04.453399Z"
        },
        "id": "MhWE8HSbwdUA",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/313 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'feature1' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Decide the epochs and learning rate\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtrain_from_scratch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTeacher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTeacher\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mtrain_from_scratch\u001b[39m\u001b[34m(model, train_loader, val_loader, epochs, learning_rate, device, model_name)\u001b[39m\n\u001b[32m     29\u001b[39m images, labels = images.to(device), labels.to(device)\n\u001b[32m     30\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m logits, hidden = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m loss = criterion(logits, labels)\n\u001b[32m     33\u001b[39m loss.backward()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mResNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# 1. Finish the forward pass and return the output layer as well as hidden features.\u001b[39;00m\n\u001b[32m     40\u001b[39m     \u001b[38;5;66;03m# 2. The output layer and hidden features will be used later for distilling.\u001b[39;00m\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# 3. You can refer to the ResNet structure illustration to finish it.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x, [\u001b[43mfeature1\u001b[49m, feature2, feature3, feature4]\n",
            "\u001b[31mNameError\u001b[39m: name 'feature1' is not defined"
          ]
        }
      ],
      "source": [
        "# Decide the epochs and learning rate\n",
        "train_from_scratch(Teacher, train_loader, val_loader, epochs=30 , learning_rate= 0.01, device=device, model_name=\"Teacher\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:21:04.474123Z",
          "iopub.status.busy": "2025-09-15T17:21:04.473894Z",
          "iopub.status.idle": "2025-09-15T17:21:17.055237Z",
          "shell.execute_reply": "2025-09-15T17:21:17.054314Z",
          "shell.execute_reply.started": "2025-09-15T17:21:04.474108Z"
        },
        "id": "_PWsWuLqwdUA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "T_loss, T_accuracy = test(Teacher, test_loader, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L43plN89wdUA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Decide the epochs and learning rate\n",
        "train_from_scratch(Student, train_loader, val_loader, epochs= , learning_rate= , device=device, model_name=\"Student\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:29:33.367646Z",
          "iopub.status.busy": "2025-09-15T17:29:33.367451Z",
          "iopub.status.idle": "2025-09-15T17:29:37.666896Z",
          "shell.execute_reply": "2025-09-15T17:29:37.666154Z",
          "shell.execute_reply.started": "2025-09-15T17:29:33.367631Z"
        },
        "id": "HJRhHt-qwdUA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "S_loss, S_accuracy = test(Student, test_loader, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmoN20JuwdUA"
      },
      "source": [
        "## Define distillation\n",
        "\n",
        "### Define the loss functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:29:37.668077Z",
          "iopub.status.busy": "2025-09-15T17:29:37.667767Z",
          "iopub.status.idle": "2025-09-15T17:29:37.672753Z",
          "shell.execute_reply": "2025-09-15T17:29:37.672224Z",
          "shell.execute_reply.started": "2025-09-15T17:29:37.668052Z"
        },
        "id": "2Jjd5o-KwdUA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Finish the loss function for response-based distillation.\n",
        "def loss_re():\n",
        "    T = # Set temperature parameter\n",
        "    alpha = # Set weighting parameter\n",
        "\n",
        "    # Implement loss calculation\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:29:37.692627Z",
          "iopub.status.busy": "2025-09-15T17:29:37.692345Z",
          "iopub.status.idle": "2025-09-15T17:29:37.712250Z",
          "shell.execute_reply": "2025-09-15T17:29:37.711759Z",
          "shell.execute_reply.started": "2025-09-15T17:29:37.692603Z"
        },
        "id": "otjdqnDFwdUA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Finish the loss function for feature-based distillation.\n",
        "def loss_fe():\n",
        "\n",
        "    # Implement loss calculation whatever you prefer\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhIgoti0wdUA"
      },
      "source": [
        "### Define Distillation Framework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:29:37.713139Z",
          "iopub.status.busy": "2025-09-15T17:29:37.712911Z",
          "iopub.status.idle": "2025-09-15T17:29:37.738648Z",
          "shell.execute_reply": "2025-09-15T17:29:37.738135Z",
          "shell.execute_reply.started": "2025-09-15T17:29:37.713114Z"
        },
        "id": "lPkIXEXPwdUA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class Distiller(nn.Module):\n",
        "    def __init__(self, teacher, student, type):\n",
        "        super(Distiller, self).__init__()\n",
        "\n",
        "        # 1. Finish the __init__ method.\n",
        "\n",
        "    def forward(self, x, target):\n",
        "        # 2. Finish the forward pass.\n",
        "\n",
        "        if self.type == 'response':\n",
        "            loss_distill = # call the loss_re()\n",
        "        elif self.type == 'feature':\n",
        "            loss_distill = # call the loss_re()\n",
        "        else:\n",
        "            raise ValueError(f'Error: only support response-based and feature-based distillation')\n",
        "\n",
        "        return student_logits, loss_distill"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQHEAueSwdUB"
      },
      "source": [
        "### Training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:29:37.739676Z",
          "iopub.status.busy": "2025-09-15T17:29:37.739468Z",
          "iopub.status.idle": "2025-09-15T17:29:37.757328Z",
          "shell.execute_reply": "2025-09-15T17:29:37.756798Z",
          "shell.execute_reply.started": "2025-09-15T17:29:37.739661Z"
        },
        "id": "3sIn7IJXwdUB",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def train_distillation(distiller, student, train_loader, val_loader, epochs, learning_rate, device):\n",
        "    ce_loss = nn.CrossEntropyLoss()\n",
        "    # define the parameter the optimizer used\n",
        "    optimizer = torch.optim.Adam( , lr=learning_rate)\n",
        "\n",
        "    loss = []\n",
        "    train_error=[]\n",
        "    val_error = []\n",
        "    valdation_error = []\n",
        "    train_loss = []\n",
        "    valdation_loss = []\n",
        "    train_accuraacy = []\n",
        "    valdation_accuracy= []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        distiller.train()\n",
        "        distiller.teacher.train()\n",
        "        distiller.student.train()\n",
        "\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        train_acc = 0.0\n",
        "        valid_acc  = 0.0\n",
        "        correct = 0.\n",
        "        total = 0.\n",
        "        V_correct = 0.\n",
        "        V_total = 0.\n",
        "        train_bar = tqdm(train_loader, file=sys.stdout)\n",
        "        for step, data in enumerate(train_bar):\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs, loss = distiller(images, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * images.size(0)\n",
        "            pred = outputs.data.max(1, keepdim=True)[1]\n",
        "            result = pred.eq(labels.data.view_as(pred))\n",
        "            result = np.squeeze(result.cpu().numpy())\n",
        "            correct += np.sum(result)\n",
        "            total += images.size(0)\n",
        "            train_bar.desc = \"train epoch[{}/{}]\".format(epoch + 1, epochs)\n",
        "\n",
        "        distiller.eval()\n",
        "        distiller.teacher.eval()\n",
        "        distiller.student.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            val_bar = tqdm(val_loader, file=sys.stdout)\n",
        "            for val_data in val_bar:\n",
        "\n",
        "                val_images, val_labels = val_data\n",
        "                val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
        "\n",
        "                outputs, loss = distiller(val_images, val_labels)\n",
        "\n",
        "                valid_loss += loss.item() * val_images.size(0)\n",
        "                pred = outputs.max(1, keepdim=True)[1]\n",
        "                V_correct += np.sum(np.squeeze(pred.eq(val_labels.data.view_as(pred))).cpu().numpy())\n",
        "                V_total += val_images.size(0)\n",
        "                val_bar.desc = \"valid epoch[{}/{}]\".format(epoch + 1, epochs)\n",
        "\n",
        "        train_loss = train_loss / len(train_loader.dataset)\n",
        "        train_error.append(train_loss)\n",
        "        valid_loss = valid_loss / len(val_loader.dataset)\n",
        "        val_error.append(valid_loss)\n",
        "        train_accuraacy.append( correct / total)\n",
        "        valdation_accuracy.append(V_correct / V_total)\n",
        "\n",
        "        print('\\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(train_loss, valid_loss))\n",
        "        print('\\tTrain Accuracy: %.3fd%% (%2d/%2d)\\tValdation Accuracy: %.3fd%% (%2d/%2d) '% (100. * correct / total, correct, total, 100. * V_correct / V_total, V_correct, V_total))\n",
        "\n",
        "    print('Finished Distilling')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "At2fwU4LwdUB"
      },
      "source": [
        "## Response-based distillation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRN7odFawdUB",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Decide the epochs and learning rate\n",
        "Student_re = resnet18(num_classes=10)\n",
        "Student_re = Student_re.to(device)\n",
        "distiller_re = Distiller(Teacher, Student_re, type='response')\n",
        "train_distillation(distiller_re, Student_re, train_loader, val_loader, epochs= , learning_rate= , device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:46:23.908450Z",
          "iopub.status.busy": "2025-09-15T17:46:23.908252Z",
          "iopub.status.idle": "2025-09-15T17:46:37.767639Z",
          "shell.execute_reply": "2025-09-15T17:46:37.767023Z",
          "shell.execute_reply.started": "2025-09-15T17:46:23.908424Z"
        },
        "id": "uSwU5ooswdUO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "reS_loss, reS_accuracy = test(distiller_re, test_loader, type='distiller', device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdisKpMOwdUP"
      },
      "source": [
        "## Feature-based distillation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpshhQrNwdUP",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Decide the epochs and learning rate\n",
        "Student_fe = resnet18(num_classes=10)\n",
        "Student_fe = Student_fe.to(device)\n",
        "distiller_fe = Distiller(Teacher, Student_fe, type='feature')\n",
        "train_distillation(distiller_fe, Student_fe, train_loader, val_loader, epochs= , learning_rate= , device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T18:12:41.350107Z",
          "iopub.status.busy": "2025-09-15T18:12:41.349535Z",
          "iopub.status.idle": "2025-09-15T18:12:56.380748Z",
          "shell.execute_reply": "2025-09-15T18:12:56.380147Z",
          "shell.execute_reply.started": "2025-09-15T18:12:41.350082Z"
        },
        "id": "zM9-xs6SwdUP",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "ftS_loss, ftS_accuracy = test(distiller_fe, test_loader, type='distiller', device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4X7OsAvhwdUP"
      },
      "source": [
        "## Result and Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T18:12:56.382324Z",
          "iopub.status.busy": "2025-09-15T18:12:56.381931Z",
          "iopub.status.idle": "2025-09-15T18:12:56.387139Z",
          "shell.execute_reply": "2025-09-15T18:12:56.386278Z",
          "shell.execute_reply.started": "2025-09-15T18:12:56.382306Z"
        },
        "id": "nsK1wsDmwdUP",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(f'Teacher from scratch: loss = {T_loss:.2f}, accuracy = {T_accuracy:.2f}')\n",
        "print(f'Student from scratch: loss = {S_loss:.2f}, accuracy = {S_accuracy:.2f}')\n",
        "print(f'Response-based student: loss = {reS_loss:.2f}, accuracy = {reS_accuracy:.2f}')\n",
        "print(f'Featured-based student: loss = {ftS_loss:.2f}, accuracy = {ftS_accuracy:.2f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "isSourceIdPinned": true,
          "modelId": 450656,
          "modelInstanceId": 433802,
          "sourceId": 581181,
          "sourceType": "modelInstanceVersion"
        }
      ],
      "dockerImageVersionId": 31090,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

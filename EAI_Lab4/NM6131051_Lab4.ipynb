{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgVOunpmwdT5"
      },
      "source": [
        "# Knowledge Distillation\n",
        "- The concept of **knowledge distillation** is to utilize class probabilities of a higher-capacity model (teacher) as soft targets of a smaller model (student)\n",
        "- The implement processes can be divided into several stages:\n",
        "  1. Finish the `ResNet()` classes\n",
        "  2. Train the teacher model (ResNet50) and the student model (ResNet18) from scratch, i.e. **without KD**\n",
        "  3. Define the `Distiller()` class and `loss_re()`, `loss_fe()` functions\n",
        "  4. Train the student model **with KD** from the teacher model in two different ways, response-based and feature based distillation\n",
        "  5. Comparison of student models w/ & w/o KD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w40lLxA3wdT7"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:20:41.614280Z",
          "iopub.status.busy": "2025-09-15T17:20:41.614011Z",
          "iopub.status.idle": "2025-09-15T17:20:46.740522Z",
          "shell.execute_reply": "2025-09-15T17:20:46.739828Z",
          "shell.execute_reply.started": "2025-09-15T17:20:41.614239Z"
        },
        "id": "xAYyvlYlwdT8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# ! pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-09-15T17:20:46.742442Z",
          "iopub.status.busy": "2025-09-15T17:20:46.742139Z",
          "iopub.status.idle": "2025-09-15T17:20:56.618435Z",
          "shell.execute_reply": "2025-09-15T17:20:56.617889Z",
          "shell.execute_reply.started": "2025-09-15T17:20:46.742411Z"
        },
        "id": "NivvmktxwdT9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms, models\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchinfo import summary\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:20:56.619518Z",
          "iopub.status.busy": "2025-09-15T17:20:56.619135Z",
          "iopub.status.idle": "2025-09-15T17:20:56.709343Z",
          "shell.execute_reply": "2025-09-15T17:20:56.708758Z",
          "shell.execute_reply.started": "2025-09-15T17:20:56.619491Z"
        },
        "id": "3n9ohVimwdT9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npQT5vdwwdT9"
      },
      "source": [
        "## Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:20:56.711171Z",
          "iopub.status.busy": "2025-09-15T17:20:56.710947Z",
          "iopub.status.idle": "2025-09-15T17:21:02.244060Z",
          "shell.execute_reply": "2025-09-15T17:21:02.243410Z",
          "shell.execute_reply.started": "2025-09-15T17:20:56.711154Z"
        },
        "id": "4WprgXfzwdT9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "validation_split = 0.2\n",
        "batch_size = 128\n",
        "\n",
        "# data augmentation and normalization\n",
        "transform_train = transforms.Compose([\n",
        "                    transforms.RandomCrop(32, padding=4),\n",
        "                    transforms.RandomHorizontalFlip(),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# download dataset\n",
        "train_and_val_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='dataset/',\n",
        "    train=True,\n",
        "    transform=transform_train,\n",
        "    download=True\n",
        ")\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='dataset/',\n",
        "    train=False,\n",
        "    transform=transform_test,\n",
        "    download=True\n",
        ")\n",
        "\n",
        "# split train and validation dataset\n",
        "train_size = int((1 - validation_split) * len(train_and_val_dataset))\n",
        "val_size = len(train_and_val_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(train_and_val_dataset, [train_size, val_size])\n",
        "\n",
        "# create dataLoader\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "test_num = len(test_dataset)\n",
        "test_steps = len(test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dz3sXl-pwdT9"
      },
      "source": [
        "## Create teacher and student models\n",
        "### Define BottleNeck for ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:21:02.245043Z",
          "iopub.status.busy": "2025-09-15T17:21:02.244775Z",
          "iopub.status.idle": "2025-09-15T17:21:02.252293Z",
          "shell.execute_reply": "2025-09-15T17:21:02.251546Z",
          "shell.execute_reply.started": "2025-09-15T17:21:02.245018Z"
        },
        "id": "xNQHKkcVwdT9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class BottleNeck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_channel, out_channel, stride=1, downsample=None, **kwargs):\n",
        "        super(BottleNeck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=1, stride=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
        "        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
        "        self.conv3 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel * self.expansion, kernel_size=1, stride=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channel * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIZdxOh-wdT-"
      },
      "source": [
        "### Define Resifual Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:21:02.253296Z",
          "iopub.status.busy": "2025-09-15T17:21:02.253067Z",
          "iopub.status.idle": "2025-09-15T17:21:02.277396Z",
          "shell.execute_reply": "2025-09-15T17:21:02.276882Z",
          "shell.execute_reply.started": "2025-09-15T17:21:02.253273Z"
        },
        "id": "wkJimDp7wdT-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channel, out_channel, stride=1, downsample=None, **kwargs):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKwQR8oKwdT-"
      },
      "source": [
        "### Define ResNet Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:21:02.278332Z",
          "iopub.status.busy": "2025-09-15T17:21:02.278077Z",
          "iopub.status.idle": "2025-09-15T17:21:02.301112Z",
          "shell.execute_reply": "2025-09-15T17:21:02.300587Z",
          "shell.execute_reply.started": "2025-09-15T17:21:02.278307Z"
        },
        "id": "neQ5KljZwdT-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, blocks_num, num_classes=1000):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channel = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, self.in_channel, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_channel)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, blocks_num[0])\n",
        "        self.layer2 = self._make_layer(block, 128, blocks_num[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, blocks_num[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, blocks_num[3], stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "\n",
        "    def _make_layer(self, block, channel, block_num, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.in_channel != channel * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channel, channel * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(channel * block.expansion))\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channel, channel, downsample=downsample, stride=stride))\n",
        "        self.in_channel = channel * block.expansion\n",
        "\n",
        "        for _ in range(1, block_num):\n",
        "            layers.append(block(self.in_channel, channel))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 1. Finish the forward pass and return the output layer as well as hidden features.\n",
        "        # 2. The output layer and hidden features will be used later for distilling.\n",
        "        # 3. You can refer to the ResNet structure illustration to finish it.\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        #layer output\n",
        "        feature1 = self.layer1(x)\n",
        "        feature2 = self.layer2(feature1)\n",
        "        feature3 = self.layer3(feature2)\n",
        "        feature4 = self.layer4(feature3)\n",
        "\n",
        "        out = self.avgpool(feature4)\n",
        "        out = torch.flatten(out, 1)\n",
        "        x = self.fc(out)\n",
        "        return x, [feature1, feature2, feature3, feature4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOy4lBgSwdT-"
      },
      "source": [
        "### Define ResNet50 and Resnet18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:21:02.302108Z",
          "iopub.status.busy": "2025-09-15T17:21:02.301868Z",
          "iopub.status.idle": "2025-09-15T17:21:02.321736Z",
          "shell.execute_reply": "2025-09-15T17:21:02.321258Z",
          "shell.execute_reply.started": "2025-09-15T17:21:02.302092Z"
        },
        "id": "WmkTpoYzwdT-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def resnet18(num_classes=10):\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n",
        "\n",
        "def resnet50(num_classes=10):\n",
        "    return ResNet(BottleNeck, [3, 4, 6, 3], num_classes=num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vzi6uxFwdT-"
      },
      "source": [
        "## Teacher Model (ResNet50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:21:02.322519Z",
          "iopub.status.busy": "2025-09-15T17:21:02.322350Z",
          "iopub.status.idle": "2025-09-15T17:21:04.197301Z",
          "shell.execute_reply": "2025-09-15T17:21:04.196547Z",
          "shell.execute_reply.started": "2025-09-15T17:21:02.322505Z"
        },
        "id": "1UaF4WGXwdT-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "Teacher = resnet50(num_classes=10)  # commment out this line if loading trained teacher model\n",
        "# Teacher = torch.load('Teacher.pt', weights_only=False)  # loading trained teacher model\n",
        "Teacher = Teacher.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dmwXM_WtwdT_",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "ResNet                                   --\n",
              "├─Conv2d: 1-1                            1,728\n",
              "├─BatchNorm2d: 1-2                       128\n",
              "├─ReLU: 1-3                              --\n",
              "├─MaxPool2d: 1-4                         --\n",
              "├─Sequential: 1-5                        --\n",
              "│    └─BottleNeck: 2-1                   --\n",
              "│    │    └─Conv2d: 3-1                  4,096\n",
              "│    │    └─BatchNorm2d: 3-2             128\n",
              "│    │    └─Conv2d: 3-3                  36,864\n",
              "│    │    └─BatchNorm2d: 3-4             128\n",
              "│    │    └─Conv2d: 3-5                  16,384\n",
              "│    │    └─BatchNorm2d: 3-6             512\n",
              "│    │    └─ReLU: 3-7                    --\n",
              "│    │    └─Sequential: 3-8              16,896\n",
              "│    └─BottleNeck: 2-2                   --\n",
              "│    │    └─Conv2d: 3-9                  16,384\n",
              "│    │    └─BatchNorm2d: 3-10            128\n",
              "│    │    └─Conv2d: 3-11                 36,864\n",
              "│    │    └─BatchNorm2d: 3-12            128\n",
              "│    │    └─Conv2d: 3-13                 16,384\n",
              "│    │    └─BatchNorm2d: 3-14            512\n",
              "│    │    └─ReLU: 3-15                   --\n",
              "│    └─BottleNeck: 2-3                   --\n",
              "│    │    └─Conv2d: 3-16                 16,384\n",
              "│    │    └─BatchNorm2d: 3-17            128\n",
              "│    │    └─Conv2d: 3-18                 36,864\n",
              "│    │    └─BatchNorm2d: 3-19            128\n",
              "│    │    └─Conv2d: 3-20                 16,384\n",
              "│    │    └─BatchNorm2d: 3-21            512\n",
              "│    │    └─ReLU: 3-22                   --\n",
              "├─Sequential: 1-6                        --\n",
              "│    └─BottleNeck: 2-4                   --\n",
              "│    │    └─Conv2d: 3-23                 32,768\n",
              "│    │    └─BatchNorm2d: 3-24            256\n",
              "│    │    └─Conv2d: 3-25                 147,456\n",
              "│    │    └─BatchNorm2d: 3-26            256\n",
              "│    │    └─Conv2d: 3-27                 65,536\n",
              "│    │    └─BatchNorm2d: 3-28            1,024\n",
              "│    │    └─ReLU: 3-29                   --\n",
              "│    │    └─Sequential: 3-30             132,096\n",
              "│    └─BottleNeck: 2-5                   --\n",
              "│    │    └─Conv2d: 3-31                 65,536\n",
              "│    │    └─BatchNorm2d: 3-32            256\n",
              "│    │    └─Conv2d: 3-33                 147,456\n",
              "│    │    └─BatchNorm2d: 3-34            256\n",
              "│    │    └─Conv2d: 3-35                 65,536\n",
              "│    │    └─BatchNorm2d: 3-36            1,024\n",
              "│    │    └─ReLU: 3-37                   --\n",
              "│    └─BottleNeck: 2-6                   --\n",
              "│    │    └─Conv2d: 3-38                 65,536\n",
              "│    │    └─BatchNorm2d: 3-39            256\n",
              "│    │    └─Conv2d: 3-40                 147,456\n",
              "│    │    └─BatchNorm2d: 3-41            256\n",
              "│    │    └─Conv2d: 3-42                 65,536\n",
              "│    │    └─BatchNorm2d: 3-43            1,024\n",
              "│    │    └─ReLU: 3-44                   --\n",
              "│    └─BottleNeck: 2-7                   --\n",
              "│    │    └─Conv2d: 3-45                 65,536\n",
              "│    │    └─BatchNorm2d: 3-46            256\n",
              "│    │    └─Conv2d: 3-47                 147,456\n",
              "│    │    └─BatchNorm2d: 3-48            256\n",
              "│    │    └─Conv2d: 3-49                 65,536\n",
              "│    │    └─BatchNorm2d: 3-50            1,024\n",
              "│    │    └─ReLU: 3-51                   --\n",
              "├─Sequential: 1-7                        --\n",
              "│    └─BottleNeck: 2-8                   --\n",
              "│    │    └─Conv2d: 3-52                 131,072\n",
              "│    │    └─BatchNorm2d: 3-53            512\n",
              "│    │    └─Conv2d: 3-54                 589,824\n",
              "│    │    └─BatchNorm2d: 3-55            512\n",
              "│    │    └─Conv2d: 3-56                 262,144\n",
              "│    │    └─BatchNorm2d: 3-57            2,048\n",
              "│    │    └─ReLU: 3-58                   --\n",
              "│    │    └─Sequential: 3-59             526,336\n",
              "│    └─BottleNeck: 2-9                   --\n",
              "│    │    └─Conv2d: 3-60                 262,144\n",
              "│    │    └─BatchNorm2d: 3-61            512\n",
              "│    │    └─Conv2d: 3-62                 589,824\n",
              "│    │    └─BatchNorm2d: 3-63            512\n",
              "│    │    └─Conv2d: 3-64                 262,144\n",
              "│    │    └─BatchNorm2d: 3-65            2,048\n",
              "│    │    └─ReLU: 3-66                   --\n",
              "│    └─BottleNeck: 2-10                  --\n",
              "│    │    └─Conv2d: 3-67                 262,144\n",
              "│    │    └─BatchNorm2d: 3-68            512\n",
              "│    │    └─Conv2d: 3-69                 589,824\n",
              "│    │    └─BatchNorm2d: 3-70            512\n",
              "│    │    └─Conv2d: 3-71                 262,144\n",
              "│    │    └─BatchNorm2d: 3-72            2,048\n",
              "│    │    └─ReLU: 3-73                   --\n",
              "│    └─BottleNeck: 2-11                  --\n",
              "│    │    └─Conv2d: 3-74                 262,144\n",
              "│    │    └─BatchNorm2d: 3-75            512\n",
              "│    │    └─Conv2d: 3-76                 589,824\n",
              "│    │    └─BatchNorm2d: 3-77            512\n",
              "│    │    └─Conv2d: 3-78                 262,144\n",
              "│    │    └─BatchNorm2d: 3-79            2,048\n",
              "│    │    └─ReLU: 3-80                   --\n",
              "│    └─BottleNeck: 2-12                  --\n",
              "│    │    └─Conv2d: 3-81                 262,144\n",
              "│    │    └─BatchNorm2d: 3-82            512\n",
              "│    │    └─Conv2d: 3-83                 589,824\n",
              "│    │    └─BatchNorm2d: 3-84            512\n",
              "│    │    └─Conv2d: 3-85                 262,144\n",
              "│    │    └─BatchNorm2d: 3-86            2,048\n",
              "│    │    └─ReLU: 3-87                   --\n",
              "│    └─BottleNeck: 2-13                  --\n",
              "│    │    └─Conv2d: 3-88                 262,144\n",
              "│    │    └─BatchNorm2d: 3-89            512\n",
              "│    │    └─Conv2d: 3-90                 589,824\n",
              "│    │    └─BatchNorm2d: 3-91            512\n",
              "│    │    └─Conv2d: 3-92                 262,144\n",
              "│    │    └─BatchNorm2d: 3-93            2,048\n",
              "│    │    └─ReLU: 3-94                   --\n",
              "├─Sequential: 1-8                        --\n",
              "│    └─BottleNeck: 2-14                  --\n",
              "│    │    └─Conv2d: 3-95                 524,288\n",
              "│    │    └─BatchNorm2d: 3-96            1,024\n",
              "│    │    └─Conv2d: 3-97                 2,359,296\n",
              "│    │    └─BatchNorm2d: 3-98            1,024\n",
              "│    │    └─Conv2d: 3-99                 1,048,576\n",
              "│    │    └─BatchNorm2d: 3-100           4,096\n",
              "│    │    └─ReLU: 3-101                  --\n",
              "│    │    └─Sequential: 3-102            2,101,248\n",
              "│    └─BottleNeck: 2-15                  --\n",
              "│    │    └─Conv2d: 3-103                1,048,576\n",
              "│    │    └─BatchNorm2d: 3-104           1,024\n",
              "│    │    └─Conv2d: 3-105                2,359,296\n",
              "│    │    └─BatchNorm2d: 3-106           1,024\n",
              "│    │    └─Conv2d: 3-107                1,048,576\n",
              "│    │    └─BatchNorm2d: 3-108           4,096\n",
              "│    │    └─ReLU: 3-109                  --\n",
              "│    └─BottleNeck: 2-16                  --\n",
              "│    │    └─Conv2d: 3-110                1,048,576\n",
              "│    │    └─BatchNorm2d: 3-111           1,024\n",
              "│    │    └─Conv2d: 3-112                2,359,296\n",
              "│    │    └─BatchNorm2d: 3-113           1,024\n",
              "│    │    └─Conv2d: 3-114                1,048,576\n",
              "│    │    └─BatchNorm2d: 3-115           4,096\n",
              "│    │    └─ReLU: 3-116                  --\n",
              "├─AdaptiveAvgPool2d: 1-9                 --\n",
              "├─Linear: 1-10                           20,490\n",
              "=================================================================\n",
              "Total params: 23,520,842\n",
              "Trainable params: 23,520,842\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary(Teacher)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZ4wlBakwdT_"
      },
      "source": [
        "## Student Model (ResNet18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:21:04.213935Z",
          "iopub.status.busy": "2025-09-15T17:21:04.213631Z",
          "iopub.status.idle": "2025-09-15T17:21:04.400068Z",
          "shell.execute_reply": "2025-09-15T17:21:04.399483Z",
          "shell.execute_reply.started": "2025-09-15T17:21:04.213911Z"
        },
        "id": "QsBS9LxPwdT_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "Student = resnet18(num_classes=10)  # commment out this line if loading trained student model\n",
        "# Student = torch.load('Student.pt', weights_only=False)  # loading trained student model\n",
        "Student = Student.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OJ8nTtDswdT_",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "ResNet                                   --\n",
              "├─Conv2d: 1-1                            1,728\n",
              "├─BatchNorm2d: 1-2                       128\n",
              "├─ReLU: 1-3                              --\n",
              "├─MaxPool2d: 1-4                         --\n",
              "├─Sequential: 1-5                        --\n",
              "│    └─BasicBlock: 2-1                   --\n",
              "│    │    └─Conv2d: 3-1                  36,864\n",
              "│    │    └─BatchNorm2d: 3-2             128\n",
              "│    │    └─ReLU: 3-3                    --\n",
              "│    │    └─Conv2d: 3-4                  36,864\n",
              "│    │    └─BatchNorm2d: 3-5             128\n",
              "│    └─BasicBlock: 2-2                   --\n",
              "│    │    └─Conv2d: 3-6                  36,864\n",
              "│    │    └─BatchNorm2d: 3-7             128\n",
              "│    │    └─ReLU: 3-8                    --\n",
              "│    │    └─Conv2d: 3-9                  36,864\n",
              "│    │    └─BatchNorm2d: 3-10            128\n",
              "├─Sequential: 1-6                        --\n",
              "│    └─BasicBlock: 2-3                   --\n",
              "│    │    └─Conv2d: 3-11                 73,728\n",
              "│    │    └─BatchNorm2d: 3-12            256\n",
              "│    │    └─ReLU: 3-13                   --\n",
              "│    │    └─Conv2d: 3-14                 147,456\n",
              "│    │    └─BatchNorm2d: 3-15            256\n",
              "│    │    └─Sequential: 3-16             8,448\n",
              "│    └─BasicBlock: 2-4                   --\n",
              "│    │    └─Conv2d: 3-17                 147,456\n",
              "│    │    └─BatchNorm2d: 3-18            256\n",
              "│    │    └─ReLU: 3-19                   --\n",
              "│    │    └─Conv2d: 3-20                 147,456\n",
              "│    │    └─BatchNorm2d: 3-21            256\n",
              "├─Sequential: 1-7                        --\n",
              "│    └─BasicBlock: 2-5                   --\n",
              "│    │    └─Conv2d: 3-22                 294,912\n",
              "│    │    └─BatchNorm2d: 3-23            512\n",
              "│    │    └─ReLU: 3-24                   --\n",
              "│    │    └─Conv2d: 3-25                 589,824\n",
              "│    │    └─BatchNorm2d: 3-26            512\n",
              "│    │    └─Sequential: 3-27             33,280\n",
              "│    └─BasicBlock: 2-6                   --\n",
              "│    │    └─Conv2d: 3-28                 589,824\n",
              "│    │    └─BatchNorm2d: 3-29            512\n",
              "│    │    └─ReLU: 3-30                   --\n",
              "│    │    └─Conv2d: 3-31                 589,824\n",
              "│    │    └─BatchNorm2d: 3-32            512\n",
              "├─Sequential: 1-8                        --\n",
              "│    └─BasicBlock: 2-7                   --\n",
              "│    │    └─Conv2d: 3-33                 1,179,648\n",
              "│    │    └─BatchNorm2d: 3-34            1,024\n",
              "│    │    └─ReLU: 3-35                   --\n",
              "│    │    └─Conv2d: 3-36                 2,359,296\n",
              "│    │    └─BatchNorm2d: 3-37            1,024\n",
              "│    │    └─Sequential: 3-38             132,096\n",
              "│    └─BasicBlock: 2-8                   --\n",
              "│    │    └─Conv2d: 3-39                 2,359,296\n",
              "│    │    └─BatchNorm2d: 3-40            1,024\n",
              "│    │    └─ReLU: 3-41                   --\n",
              "│    │    └─Conv2d: 3-42                 2,359,296\n",
              "│    │    └─BatchNorm2d: 3-43            1,024\n",
              "├─AdaptiveAvgPool2d: 1-9                 --\n",
              "├─Linear: 1-10                           5,130\n",
              "=================================================================\n",
              "Total params: 11,173,962\n",
              "Trainable params: 11,173,962\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary(Student)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qF1RPSfrwdT_"
      },
      "source": [
        "## Define training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:21:04.411876Z",
          "iopub.status.busy": "2025-09-15T17:21:04.411049Z",
          "iopub.status.idle": "2025-09-15T17:21:04.429748Z",
          "shell.execute_reply": "2025-09-15T17:21:04.429207Z",
          "shell.execute_reply.started": "2025-09-15T17:21:04.411856Z"
        },
        "id": "sYihMy4lwdT_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def train_from_scratch(model, train_loader, val_loader, epochs, learning_rate, device, model_name):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = torch.optim.Adam(params, lr=learning_rate)\n",
        "\n",
        "    loss = []\n",
        "    train_error=[]\n",
        "    val_error = []\n",
        "    valdation_error = []\n",
        "    train_loss = []\n",
        "    valdation_loss = []\n",
        "    train_accuraacy = []\n",
        "    valdation_accuracy= []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        train_acc = 0.0\n",
        "        valid_acc = 0.0\n",
        "        correct = 0.\n",
        "        total = 0.\n",
        "        V_correct = 0.\n",
        "        V_total = 0.\n",
        "\n",
        "        model.train()\n",
        "        train_bar = tqdm(train_loader, file=sys.stdout)\n",
        "        for step, data in enumerate(train_bar):\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits, hidden = model(images)\n",
        "            loss = criterion(logits, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * images.size(0)\n",
        "            pred = logits.data.max(1, keepdim=True)[1]\n",
        "            correct += np.sum(np.squeeze(pred.eq(labels.data.view_as(pred))).cpu().numpy())\n",
        "            total += images.size(0)\n",
        "            train_acc =  correct/total\n",
        "            train_bar.desc = \"train epoch[{}/{}]\".format(epoch + 1, epochs)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_bar = tqdm(val_loader, file=sys.stdout)\n",
        "            for val_data in val_bar:\n",
        "                val_images, val_labels = val_data\n",
        "                val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
        "                outputs, hidden_outputs = model(val_images)\n",
        "                loss = criterion(outputs, val_labels)\n",
        "                valid_loss += loss.item() * val_images.size(0)\n",
        "                pred = outputs.data.max(1, keepdim=True)[1]\n",
        "                V_correct += np.sum(np.squeeze(pred.eq(val_labels.data.view_as(pred))).cpu().numpy())\n",
        "                V_total += val_images.size(0)\n",
        "                val_bar.desc = \"valid epoch[{}/{}]\".format(epoch + 1, epochs)\n",
        "\n",
        "        train_loss = train_loss / len(train_loader.dataset)\n",
        "        train_error.append(train_loss)\n",
        "        valid_loss = valid_loss / len(val_loader.dataset)\n",
        "        val_error.append(valid_loss)\n",
        "        train_accuraacy.append( correct / total)\n",
        "        valdation_accuracy.append(V_correct / V_total)\n",
        "\n",
        "        print('\\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(train_loss, valid_loss))\n",
        "        print('\\tTrain Accuracy: %.3fd%% (%2d/%2d)\\tValdation Accuracy: %.3fd%% (%2d/%2d) '% (100. * correct / total, correct, total, 100. * V_correct / V_total, V_correct, V_total))\n",
        "\n",
        "    torch.save(model, f'{model_name}.pt')\n",
        "    print(f'{model_name}.pt is saved')\n",
        "\n",
        "    print('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJihXOROwdT_"
      },
      "source": [
        "## Define testing function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:21:04.431037Z",
          "iopub.status.busy": "2025-09-15T17:21:04.430762Z",
          "iopub.status.idle": "2025-09-15T17:21:04.452490Z",
          "shell.execute_reply": "2025-09-15T17:21:04.451992Z",
          "shell.execute_reply.started": "2025-09-15T17:21:04.431014Z"
        },
        "id": "IMcS6k_lwdT_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def test(model, test_loader ,device, type=None):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    acc = 0.0\n",
        "    test_loss = 0.0\n",
        "\n",
        "    if type == None:\n",
        "        model.eval()\n",
        "    elif type == 'distiller':\n",
        "        model.eval()\n",
        "        model.teacher.eval()\n",
        "        model.student.eval()\n",
        "    else:\n",
        "       raise ValueError(f'Error: only support response-based and feature-based distillation')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        test_bar = tqdm(test_loader, file=sys.stdout)\n",
        "        for test_data in test_bar:\n",
        "            test_images, test_labels = test_data\n",
        "            test_images, test_labels = test_images.to(device), test_labels.to(device)\n",
        "            if type == None:\n",
        "                outputs, features = model(test_images)\n",
        "                loss = criterion(outputs, test_labels)\n",
        "            elif type == 'distiller':\n",
        "                outputs, loss = model(test_images, test_labels)\n",
        "            else:\n",
        "                raise ValueError(f'Error: only support response-based and feature-based distillation')\n",
        "\n",
        "            predict_y = torch.max(outputs, dim=1)[1]\n",
        "            acc += torch.eq(predict_y, test_labels.to(device)).sum().item()\n",
        "            test_loss += loss.item()\n",
        "            test_bar.desc = \"test\"\n",
        "\n",
        "    test_accurate = acc / test_num\n",
        "    print('test_loss: %.3f  test_accuracy: %.3f' %(test_loss / test_steps, test_accurate * 100))\n",
        "    return test_loss / test_steps, test_accurate * 100."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOCKqaHXwdUA"
      },
      "source": [
        "## Train Teacher and Student model from scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:21:04.453428Z",
          "iopub.status.busy": "2025-09-15T17:21:04.453203Z",
          "iopub.status.idle": "2025-09-15T17:21:04.473303Z",
          "shell.execute_reply": "2025-09-15T17:21:04.472761Z",
          "shell.execute_reply.started": "2025-09-15T17:21:04.453399Z"
        },
        "id": "MhWE8HSbwdUA",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train epoch[1/50]: 100%|██████████| 313/313 [01:24<00:00,  3.70it/s]\n",
            "valid epoch[1/50]: 100%|██████████| 79/79 [00:13<00:00,  5.82it/s]\n",
            "\tTraining Loss: 2.377051 \tValidation Loss: 1.971177\n",
            "\tTrain Accuracy: 19.617d% (7847/40000)\tValdation Accuracy: 27.120d% (2712/10000) \n",
            "train epoch[2/50]: 100%|██████████| 313/313 [00:53<00:00,  5.84it/s]\n",
            "valid epoch[2/50]: 100%|██████████| 79/79 [00:08<00:00,  9.22it/s]\n",
            "\tTraining Loss: 1.697885 \tValidation Loss: 1.596094\n",
            "\tTrain Accuracy: 35.655d% (14262/40000)\tValdation Accuracy: 41.230d% (4123/10000) \n",
            "train epoch[3/50]:  53%|█████▎    | 167/313 [00:29<00:25,  5.67it/s]"
          ]
        }
      ],
      "source": [
        "# Decide the epochs and learning rate\n",
        "train_from_scratch(Teacher, train_loader, val_loader, epochs=50 , learning_rate= 0.01, device=device, model_name=\"Teacher1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:21:04.474123Z",
          "iopub.status.busy": "2025-09-15T17:21:04.473894Z",
          "iopub.status.idle": "2025-09-15T17:21:17.055237Z",
          "shell.execute_reply": "2025-09-15T17:21:17.054314Z",
          "shell.execute_reply.started": "2025-09-15T17:21:04.474108Z"
        },
        "id": "_PWsWuLqwdUA",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test: 100%|██████████| 79/79 [00:06<00:00, 12.07it/s]\n",
            "test_loss: 0.509  test_accuracy: 87.250\n"
          ]
        }
      ],
      "source": [
        "T_loss, T_accuracy = test(Teacher, test_loader, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L43plN89wdUA",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train epoch[1/50]: 100%|██████████| 313/313 [00:31<00:00, 10.01it/s]\n",
            "valid epoch[1/50]: 100%|██████████| 79/79 [00:05<00:00, 13.98it/s]\n",
            "\tTraining Loss: 1.399595 \tValidation Loss: 1.127607\n",
            "\tTrain Accuracy: 49.438d% (19775/40000)\tValdation Accuracy: 60.200d% (6020/10000) \n",
            "train epoch[2/50]: 100%|██████████| 313/313 [00:31<00:00, 10.03it/s]\n",
            "valid epoch[2/50]: 100%|██████████| 79/79 [00:05<00:00, 13.55it/s]\n",
            "\tTraining Loss: 0.989119 \tValidation Loss: 1.135081\n",
            "\tTrain Accuracy: 65.030d% (26012/40000)\tValdation Accuracy: 61.720d% (6172/10000) \n",
            "train epoch[3/50]: 100%|██████████| 313/313 [00:31<00:00,  9.83it/s]\n",
            "valid epoch[3/50]: 100%|██████████| 79/79 [00:05<00:00, 13.93it/s]\n",
            "\tTraining Loss: 0.808853 \tValidation Loss: 0.811021\n",
            "\tTrain Accuracy: 71.812d% (28725/40000)\tValdation Accuracy: 72.650d% (7265/10000) \n",
            "train epoch[4/50]: 100%|██████████| 313/313 [00:31<00:00,  9.94it/s]\n",
            "valid epoch[4/50]: 100%|██████████| 79/79 [00:05<00:00, 13.94it/s]\n",
            "\tTraining Loss: 0.706468 \tValidation Loss: 0.756123\n",
            "\tTrain Accuracy: 75.353d% (30141/40000)\tValdation Accuracy: 73.930d% (7393/10000) \n",
            "train epoch[5/50]: 100%|██████████| 313/313 [00:31<00:00, 10.09it/s]\n",
            "valid epoch[5/50]: 100%|██████████| 79/79 [00:05<00:00, 13.71it/s]\n",
            "\tTraining Loss: 0.635954 \tValidation Loss: 0.737927\n",
            "\tTrain Accuracy: 77.897d% (31159/40000)\tValdation Accuracy: 75.330d% (7533/10000) \n",
            "train epoch[6/50]: 100%|██████████| 313/313 [00:31<00:00,  9.90it/s]\n",
            "valid epoch[6/50]:  77%|███████▋  | 61/79 [00:04<00:01, 13.32it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[65]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Decide the epochs and learning rate\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtrain_from_scratch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mStudent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mStudent1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[59]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mtrain_from_scratch\u001b[39m\u001b[34m(model, train_loader, val_loader, epochs, learning_rate, device, model_name)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m     44\u001b[39m     val_bar = tqdm(val_loader, file=sys.stdout)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval_bar\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m        \u001b[49m\u001b[43mval_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m        \u001b[49m\u001b[43mval_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_images\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:788\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    787\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    790\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_collation:\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataset, \u001b[33m\"\u001b[39m\u001b[33m__getitems__\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__:\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     52\u001b[39m         data = [\u001b[38;5;28mself\u001b[39m.dataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/utils/data/dataset.py:416\u001b[39m, in \u001b[36mSubset.__getitems__\u001b[39m\u001b[34m(self, indices)\u001b[39m\n\u001b[32m    414\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__([\u001b[38;5;28mself\u001b[39m.indices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torchvision/datasets/cifar.py:119\u001b[39m, in \u001b[36mCIFAR10.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    116\u001b[39m img = Image.fromarray(img)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     img = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.target_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    122\u001b[39m     target = \u001b[38;5;28mself\u001b[39m.target_transform(target)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torchvision/transforms/transforms.py:95\u001b[39m, in \u001b[36mCompose.__call__\u001b[39m\u001b[34m(self, img)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         img = \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torchvision/transforms/transforms.py:681\u001b[39m, in \u001b[36mRandomCrop.forward\u001b[39m\u001b[34m(self, img)\u001b[39m\n\u001b[32m    678\u001b[39m     padding = [\u001b[32m0\u001b[39m, \u001b[38;5;28mself\u001b[39m.size[\u001b[32m0\u001b[39m] - height]\n\u001b[32m    679\u001b[39m     img = F.pad(img, padding, \u001b[38;5;28mself\u001b[39m.fill, \u001b[38;5;28mself\u001b[39m.padding_mode)\n\u001b[32m--> \u001b[39m\u001b[32m681\u001b[39m i, j, h, w = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m F.crop(img, i, j, h, w)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torchvision/transforms/transforms.py:645\u001b[39m, in \u001b[36mRandomCrop.get_params\u001b[39m\u001b[34m(img, output_size)\u001b[39m\n\u001b[32m    642\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m w == tw \u001b[38;5;129;01mand\u001b[39;00m h == th:\n\u001b[32m    643\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, h, w\n\u001b[32m--> \u001b[39m\u001b[32m645\u001b[39m i = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mth\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m.item()\n\u001b[32m    646\u001b[39m j = torch.randint(\u001b[32m0\u001b[39m, w - tw + \u001b[32m1\u001b[39m, size=(\u001b[32m1\u001b[39m,)).item()\n\u001b[32m    647\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m i, j, th, tw\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Decide the epochs and learning rate\n",
        "train_from_scratch(Student, train_loader, val_loader, epochs=50 , learning_rate= 0.01, device=device, model_name=\"Student1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:29:33.367646Z",
          "iopub.status.busy": "2025-09-15T17:29:33.367451Z",
          "iopub.status.idle": "2025-09-15T17:29:37.666896Z",
          "shell.execute_reply": "2025-09-15T17:29:37.666154Z",
          "shell.execute_reply.started": "2025-09-15T17:29:33.367631Z"
        },
        "id": "HJRhHt-qwdUA",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test: 100%|██████████| 79/79 [00:02<00:00, 26.51it/s]\n",
            "test_loss: 0.573  test_accuracy: 87.890\n"
          ]
        }
      ],
      "source": [
        "S_loss, S_accuracy = test(Student, test_loader, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmoN20JuwdUA"
      },
      "source": [
        "## Define distillation\n",
        "\n",
        "### Define the loss functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:29:37.668077Z",
          "iopub.status.busy": "2025-09-15T17:29:37.667767Z",
          "iopub.status.idle": "2025-09-15T17:29:37.672753Z",
          "shell.execute_reply": "2025-09-15T17:29:37.672224Z",
          "shell.execute_reply.started": "2025-09-15T17:29:37.668052Z"
        },
        "id": "2Jjd5o-KwdUA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Finish the loss function for response-based distillation.\n",
        "def loss_re(student_logits, teacher_logits, labels):\n",
        "    T = 10# Set temperature parameter\n",
        "    alpha = 0.8 # Set weighting parameter\n",
        "\n",
        "    # Implement loss calculation\n",
        "    Student_prob = F.log_softmax(student_logits / T, dim=1)\n",
        "    teacher_prob = F.softmax(teacher_logits / T, dim=1)\n",
        "    kd_loss = F.kl_div(Student_prob, teacher_prob, reduction='batchmean') * (T * T)\n",
        "\n",
        "    #caculate 標準分類損失（直接用原始分數算 cross-entropy，和 ground truth label 做對比。）\n",
        "    ce_loss = F.cross_entropy(student_logits, labels)\n",
        "    loss = alpha * kd_loss + (1 - alpha) * ce_loss #(1 - alpha) * ce_loss：偏向 ground-truth（教材）的部份。alpha * kd_loss：偏向模仿老師的部份。\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:29:37.692627Z",
          "iopub.status.busy": "2025-09-15T17:29:37.692345Z",
          "iopub.status.idle": "2025-09-15T17:29:37.712250Z",
          "shell.execute_reply": "2025-09-15T17:29:37.711759Z",
          "shell.execute_reply.started": "2025-09-15T17:29:37.692603Z"
        },
        "id": "otjdqnDFwdUA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Finish the loss function for feature-based distillation.\n",
        "def normalize_feature(feat):\n",
        "    norm = torch.norm(feat, p=2, dim=1, keepdim=True) + 1e-8\n",
        "    return feat / norm\n",
        "\n",
        "def loss_fe(student_features, teacher_features, adapters, student_logits, labels, alpha=0.5):\n",
        "    feature_loss = 0\n",
        "    n = len(student_features)\n",
        "    for i, (s_feat, t_feat) in enumerate(zip(student_features, teacher_features)):\n",
        "        s_feat_adapted = adapters[i](s_feat)\n",
        "        s_feat_norm = normalize_feature(s_feat_adapted)\n",
        "        t_feat_norm = normalize_feature(t_feat)\n",
        "        feature_loss += F.mse_loss(s_feat_norm, t_feat_norm)\n",
        "    feature_loss = feature_loss / n\n",
        "    ce_loss = F.cross_entropy(student_logits, labels)\n",
        "    loss = alpha * feature_loss + (1 - alpha) * ce_loss\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhIgoti0wdUA"
      },
      "source": [
        "### Define Distillation Framework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:29:37.713139Z",
          "iopub.status.busy": "2025-09-15T17:29:37.712911Z",
          "iopub.status.idle": "2025-09-15T17:29:37.738648Z",
          "shell.execute_reply": "2025-09-15T17:29:37.738135Z",
          "shell.execute_reply.started": "2025-09-15T17:29:37.713114Z"
        },
        "id": "lPkIXEXPwdUA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class Distiller(nn.Module):\n",
        "    def __init__(self, teacher, student, type):\n",
        "        super(Distiller, self).__init__()\n",
        "\n",
        "        # 1. Finish the __init__ method.\n",
        "        self.teacher = teacher\n",
        "        self.student = student\n",
        "        self.type = type\n",
        "\n",
        "        if type == 'feature':\n",
        "            device = next(student.parameters()).device\n",
        "            with torch.no_grad():\n",
        "                dummy = torch.randn(1, 3, 32, 32, device=device)\n",
        "                _, s_features = self.student(dummy)\n",
        "                _, t_features = self.teacher(dummy)\n",
        "                s_channels = [f.shape[1] for f in s_features]\n",
        "                t_channels = [f.shape[1] for f in t_features]\n",
        "            self.adapters = nn.ModuleList([\n",
        "                nn.Conv2d(s_c, t_c, kernel_size=1).to(device) if s_c != t_c else nn.Identity().to(device)\n",
        "                for s_c, t_c in zip(s_channels, t_channels)\n",
        "            ])\n",
        "        else:\n",
        "            self.adapters = None\n",
        "\n",
        "    def forward(self, x, target):\n",
        "        # 2. Finish the forward pass.\n",
        "        student_logits, student_features = self.student(x)\n",
        "        with torch.no_grad():\n",
        "            teacher_logits, teacher_features = self.teacher(x)\n",
        "        if self.type == 'response':\n",
        "            loss_distill =  loss_re(student_logits,teacher_logits,target)# call the loss_re()\n",
        "        elif self.type == 'feature':\n",
        "            loss_distill = loss_fe(student_features,teacher_features,self.adapters,student_logits,target,alpha=0.5)# call the loss_re()\n",
        "        else:\n",
        "            raise ValueError(f'Error: only support response-based and feature-based distillation')\n",
        "\n",
        "        return student_logits, loss_distill"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQHEAueSwdUB"
      },
      "source": [
        "### Training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:29:37.739676Z",
          "iopub.status.busy": "2025-09-15T17:29:37.739468Z",
          "iopub.status.idle": "2025-09-15T17:29:37.757328Z",
          "shell.execute_reply": "2025-09-15T17:29:37.756798Z",
          "shell.execute_reply.started": "2025-09-15T17:29:37.739661Z"
        },
        "id": "3sIn7IJXwdUB",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def train_distillation(distiller, student, train_loader, val_loader, epochs, learning_rate, device):\n",
        "    ce_loss = nn.CrossEntropyLoss()\n",
        "    # define the parameter the optimizer used\n",
        "    optimizer = torch.optim.Adam(student.parameters(), lr=learning_rate)\n",
        "\n",
        "    loss = []\n",
        "    train_error=[]\n",
        "    val_error = []\n",
        "    valdation_error = []\n",
        "    train_loss = []\n",
        "    valdation_loss = []\n",
        "    train_accuraacy = []\n",
        "    valdation_accuracy= []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        distiller.train()\n",
        "        distiller.teacher.train()\n",
        "        distiller.student.train()\n",
        "\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        train_acc = 0.0\n",
        "        valid_acc  = 0.0\n",
        "        correct = 0.\n",
        "        total = 0.\n",
        "        V_correct = 0.\n",
        "        V_total = 0.\n",
        "        train_bar = tqdm(train_loader, file=sys.stdout)\n",
        "        for step, data in enumerate(train_bar):\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs, loss = distiller(images, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * images.size(0)\n",
        "            pred = outputs.data.max(1, keepdim=True)[1]\n",
        "            result = pred.eq(labels.data.view_as(pred))\n",
        "            result = np.squeeze(result.cpu().numpy())\n",
        "            correct += np.sum(result)\n",
        "            total += images.size(0)\n",
        "            train_bar.desc = \"train epoch[{}/{}]\".format(epoch + 1, epochs)\n",
        "\n",
        "        distiller.eval()\n",
        "        distiller.teacher.eval()\n",
        "        distiller.student.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            val_bar = tqdm(val_loader, file=sys.stdout)\n",
        "            for val_data in val_bar:\n",
        "\n",
        "                val_images, val_labels = val_data\n",
        "                val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
        "\n",
        "                outputs, loss = distiller(val_images, val_labels)\n",
        "\n",
        "                valid_loss += loss.item() * val_images.size(0)\n",
        "                pred = outputs.max(1, keepdim=True)[1]\n",
        "                V_correct += np.sum(np.squeeze(pred.eq(val_labels.data.view_as(pred))).cpu().numpy())\n",
        "                V_total += val_images.size(0)\n",
        "                val_bar.desc = \"valid epoch[{}/{}]\".format(epoch + 1, epochs)\n",
        "\n",
        "        train_loss = train_loss / len(train_loader.dataset)\n",
        "        train_error.append(train_loss)\n",
        "        valid_loss = valid_loss / len(val_loader.dataset)\n",
        "        val_error.append(valid_loss)\n",
        "        train_accuraacy.append( correct / total)\n",
        "        valdation_accuracy.append(V_correct / V_total)\n",
        "\n",
        "        print('\\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(train_loss, valid_loss))\n",
        "        print('\\tTrain Accuracy: %.3fd%% (%2d/%2d)\\tValdation Accuracy: %.3fd%% (%2d/%2d) '% (100. * correct / total, correct, total, 100. * V_correct / V_total, V_correct, V_total))\n",
        "\n",
        "    print('Finished Distilling')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "At2fwU4LwdUB"
      },
      "source": [
        "## Response-based distillation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRN7odFawdUB",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train epoch[1/50]: 100%|██████████| 313/313 [00:19<00:00, 16.41it/s]\n",
            "valid epoch[1/50]: 100%|██████████| 79/79 [00:04<00:00, 18.70it/s]\n",
            "\tTraining Loss: 15.273459 \tValidation Loss: 13.144140\n",
            "\tTrain Accuracy: 40.877d% (16351/40000)\tValdation Accuracy: 47.090d% (4709/10000) \n",
            "train epoch[2/50]: 100%|██████████| 313/313 [00:20<00:00, 15.25it/s]\n",
            "valid epoch[2/50]: 100%|██████████| 79/79 [00:04<00:00, 18.77it/s]\n",
            "\tTraining Loss: 9.303315 \tValidation Loss: 9.395694\n",
            "\tTrain Accuracy: 59.057d% (23623/40000)\tValdation Accuracy: 59.660d% (5966/10000) \n",
            "train epoch[3/50]: 100%|██████████| 313/313 [00:21<00:00, 14.55it/s]\n",
            "valid epoch[3/50]: 100%|██████████| 79/79 [00:04<00:00, 18.76it/s]\n",
            "\tTraining Loss: 6.990948 \tValidation Loss: 7.149526\n",
            "\tTrain Accuracy: 66.705d% (26682/40000)\tValdation Accuracy: 65.500d% (6550/10000) \n",
            "train epoch[4/50]: 100%|██████████| 313/313 [00:21<00:00, 14.56it/s]\n",
            "valid epoch[4/50]: 100%|██████████| 79/79 [00:04<00:00, 18.75it/s]\n",
            "\tTraining Loss: 5.895701 \tValidation Loss: 7.022389\n",
            "\tTrain Accuracy: 70.993d% (28397/40000)\tValdation Accuracy: 66.920d% (6692/10000) \n",
            "train epoch[5/50]: 100%|██████████| 313/313 [00:21<00:00, 14.53it/s]\n",
            "valid epoch[5/50]: 100%|██████████| 79/79 [00:04<00:00, 18.76it/s]\n",
            "\tTraining Loss: 4.925787 \tValidation Loss: 4.559717\n",
            "\tTrain Accuracy: 74.830d% (29932/40000)\tValdation Accuracy: 74.770d% (7477/10000) \n",
            "train epoch[6/50]: 100%|██████████| 313/313 [00:24<00:00, 12.60it/s]\n",
            "valid epoch[6/50]: 100%|██████████| 79/79 [00:04<00:00, 18.74it/s]\n",
            "\tTraining Loss: 4.214616 \tValidation Loss: 4.310457\n",
            "\tTrain Accuracy: 77.890d% (31156/40000)\tValdation Accuracy: 75.640d% (7564/10000) \n",
            "train epoch[7/50]: 100%|██████████| 313/313 [00:23<00:00, 13.17it/s]\n",
            "valid epoch[7/50]: 100%|██████████| 79/79 [00:04<00:00, 18.84it/s]\n",
            "\tTraining Loss: 3.693613 \tValidation Loss: 3.849119\n",
            "\tTrain Accuracy: 80.233d% (32093/40000)\tValdation Accuracy: 79.100d% (7910/10000) \n",
            "train epoch[8/50]: 100%|██████████| 313/313 [00:21<00:00, 14.58it/s]\n",
            "valid epoch[8/50]: 100%|██████████| 79/79 [00:04<00:00, 18.81it/s]\n",
            "\tTraining Loss: 3.373449 \tValidation Loss: 3.313100\n",
            "\tTrain Accuracy: 81.455d% (32582/40000)\tValdation Accuracy: 79.720d% (7972/10000) \n",
            "train epoch[9/50]: 100%|██████████| 313/313 [00:21<00:00, 14.44it/s]\n",
            "valid epoch[9/50]: 100%|██████████| 79/79 [00:04<00:00, 16.97it/s]\n",
            "\tTraining Loss: 3.042881 \tValidation Loss: 3.296793\n",
            "\tTrain Accuracy: 83.255d% (33302/40000)\tValdation Accuracy: 79.650d% (7965/10000) \n",
            "train epoch[10/50]: 100%|██████████| 313/313 [00:22<00:00, 14.03it/s]\n",
            "valid epoch[10/50]: 100%|██████████| 79/79 [00:04<00:00, 17.10it/s]\n",
            "\tTraining Loss: 2.818883 \tValidation Loss: 3.030108\n",
            "\tTrain Accuracy: 84.237d% (33695/40000)\tValdation Accuracy: 81.910d% (8191/10000) \n",
            "train epoch[11/50]: 100%|██████████| 313/313 [00:22<00:00, 13.96it/s]\n",
            "valid epoch[11/50]: 100%|██████████| 79/79 [00:04<00:00, 17.09it/s]\n",
            "\tTraining Loss: 2.659273 \tValidation Loss: 2.930234\n",
            "\tTrain Accuracy: 85.005d% (34002/40000)\tValdation Accuracy: 81.470d% (8147/10000) \n",
            "train epoch[12/50]: 100%|██████████| 313/313 [00:22<00:00, 13.98it/s]\n",
            "valid epoch[12/50]: 100%|██████████| 79/79 [00:04<00:00, 17.08it/s]\n",
            "\tTraining Loss: 2.542978 \tValidation Loss: 2.767521\n",
            "\tTrain Accuracy: 85.670d% (34268/40000)\tValdation Accuracy: 83.100d% (8310/10000) \n",
            "train epoch[13/50]: 100%|██████████| 313/313 [00:22<00:00, 13.99it/s]\n",
            "valid epoch[13/50]: 100%|██████████| 79/79 [00:04<00:00, 17.09it/s]\n",
            "\tTraining Loss: 2.413244 \tValidation Loss: 2.599893\n",
            "\tTrain Accuracy: 86.010d% (34404/40000)\tValdation Accuracy: 83.120d% (8312/10000) \n",
            "train epoch[14/50]: 100%|██████████| 313/313 [00:22<00:00, 14.03it/s]\n",
            "valid epoch[14/50]: 100%|██████████| 79/79 [00:04<00:00, 17.08it/s]\n",
            "\tTraining Loss: 2.290450 \tValidation Loss: 2.499476\n",
            "\tTrain Accuracy: 86.860d% (34744/40000)\tValdation Accuracy: 83.590d% (8359/10000) \n",
            "train epoch[15/50]: 100%|██████████| 313/313 [00:22<00:00, 14.00it/s]\n",
            "valid epoch[15/50]: 100%|██████████| 79/79 [00:04<00:00, 17.10it/s]\n",
            "\tTraining Loss: 2.183727 \tValidation Loss: 2.412114\n",
            "\tTrain Accuracy: 87.403d% (34961/40000)\tValdation Accuracy: 84.170d% (8417/10000) \n",
            "train epoch[16/50]: 100%|██████████| 313/313 [00:24<00:00, 13.01it/s]\n",
            "valid epoch[16/50]: 100%|██████████| 79/79 [00:04<00:00, 17.05it/s]\n",
            "\tTraining Loss: 2.144630 \tValidation Loss: 2.720453\n",
            "\tTrain Accuracy: 87.778d% (35111/40000)\tValdation Accuracy: 83.390d% (8339/10000) \n",
            "train epoch[17/50]: 100%|██████████| 313/313 [00:22<00:00, 13.99it/s]\n",
            "valid epoch[17/50]: 100%|██████████| 79/79 [00:04<00:00, 17.12it/s]\n",
            "\tTraining Loss: 2.055233 \tValidation Loss: 2.969083\n",
            "\tTrain Accuracy: 88.375d% (35350/40000)\tValdation Accuracy: 82.260d% (8226/10000) \n",
            "train epoch[18/50]: 100%|██████████| 313/313 [00:22<00:00, 13.98it/s]\n",
            "valid epoch[18/50]: 100%|██████████| 79/79 [00:04<00:00, 16.91it/s]\n",
            "\tTraining Loss: 2.056295 \tValidation Loss: 2.986106\n",
            "\tTrain Accuracy: 88.190d% (35276/40000)\tValdation Accuracy: 84.120d% (8412/10000) \n",
            "train epoch[19/50]: 100%|██████████| 313/313 [00:22<00:00, 13.99it/s]\n",
            "valid epoch[19/50]: 100%|██████████| 79/79 [00:04<00:00, 16.30it/s]\n",
            "\tTraining Loss: 2.001439 \tValidation Loss: 2.565305\n",
            "\tTrain Accuracy: 88.530d% (35412/40000)\tValdation Accuracy: 84.090d% (8409/10000) \n",
            "train epoch[20/50]: 100%|██████████| 313/313 [00:25<00:00, 12.18it/s]\n",
            "valid epoch[20/50]: 100%|██████████| 79/79 [00:05<00:00, 14.19it/s]\n",
            "\tTraining Loss: 1.920930 \tValidation Loss: 2.410766\n",
            "\tTrain Accuracy: 89.177d% (35671/40000)\tValdation Accuracy: 83.790d% (8379/10000) \n",
            "train epoch[21/50]: 100%|██████████| 313/313 [00:25<00:00, 12.20it/s]\n",
            "valid epoch[21/50]: 100%|██████████| 79/79 [00:04<00:00, 16.35it/s]\n",
            "\tTraining Loss: 1.901045 \tValidation Loss: 2.126869\n",
            "\tTrain Accuracy: 89.295d% (35718/40000)\tValdation Accuracy: 85.300d% (8530/10000) \n",
            "train epoch[22/50]: 100%|██████████| 313/313 [00:22<00:00, 14.05it/s]\n",
            "valid epoch[22/50]: 100%|██████████| 79/79 [00:04<00:00, 17.08it/s]\n",
            "\tTraining Loss: 1.851827 \tValidation Loss: 2.054526\n",
            "\tTrain Accuracy: 89.558d% (35823/40000)\tValdation Accuracy: 85.030d% (8503/10000) \n",
            "train epoch[23/50]: 100%|██████████| 313/313 [00:22<00:00, 14.02it/s]\n",
            "valid epoch[23/50]: 100%|██████████| 79/79 [00:04<00:00, 17.13it/s]\n",
            "\tTraining Loss: 1.785469 \tValidation Loss: 2.202672\n",
            "\tTrain Accuracy: 89.880d% (35952/40000)\tValdation Accuracy: 85.180d% (8518/10000) \n",
            "train epoch[24/50]: 100%|██████████| 313/313 [00:22<00:00, 13.98it/s]\n",
            "valid epoch[24/50]: 100%|██████████| 79/79 [00:04<00:00, 16.99it/s]\n",
            "\tTraining Loss: 1.730890 \tValidation Loss: 1.951105\n",
            "\tTrain Accuracy: 90.043d% (36017/40000)\tValdation Accuracy: 85.940d% (8594/10000) \n",
            "train epoch[25/50]: 100%|██████████| 313/313 [00:22<00:00, 13.94it/s]\n",
            "valid epoch[25/50]: 100%|██████████| 79/79 [00:04<00:00, 16.59it/s]\n",
            "\tTraining Loss: 1.721749 \tValidation Loss: 2.166823\n",
            "\tTrain Accuracy: 90.360d% (36144/40000)\tValdation Accuracy: 85.090d% (8509/10000) \n",
            "train epoch[26/50]: 100%|██████████| 313/313 [00:24<00:00, 12.72it/s]\n",
            "valid epoch[26/50]: 100%|██████████| 79/79 [00:04<00:00, 16.94it/s]\n",
            "\tTraining Loss: 1.709333 \tValidation Loss: 2.063956\n",
            "\tTrain Accuracy: 90.575d% (36230/40000)\tValdation Accuracy: 86.320d% (8632/10000) \n",
            "train epoch[27/50]: 100%|██████████| 313/313 [00:22<00:00, 14.03it/s]\n",
            "valid epoch[27/50]: 100%|██████████| 79/79 [00:04<00:00, 16.96it/s]\n",
            "\tTraining Loss: 1.665503 \tValidation Loss: 2.054160\n",
            "\tTrain Accuracy: 90.808d% (36323/40000)\tValdation Accuracy: 86.430d% (8643/10000) \n",
            "train epoch[28/50]: 100%|██████████| 313/313 [00:22<00:00, 14.08it/s]\n",
            "valid epoch[28/50]: 100%|██████████| 79/79 [00:04<00:00, 16.84it/s]\n",
            "\tTraining Loss: 1.650333 \tValidation Loss: 1.862255\n",
            "\tTrain Accuracy: 90.785d% (36314/40000)\tValdation Accuracy: 86.170d% (8617/10000) \n",
            "train epoch[29/50]: 100%|██████████| 313/313 [00:22<00:00, 13.96it/s]\n",
            "valid epoch[29/50]: 100%|██████████| 79/79 [00:04<00:00, 16.90it/s]\n",
            "\tTraining Loss: 1.596914 \tValidation Loss: 1.796240\n",
            "\tTrain Accuracy: 91.140d% (36456/40000)\tValdation Accuracy: 85.970d% (8597/10000) \n",
            "train epoch[30/50]: 100%|██████████| 313/313 [00:22<00:00, 13.95it/s]\n",
            "valid epoch[30/50]: 100%|██████████| 79/79 [00:04<00:00, 17.16it/s]\n",
            "\tTraining Loss: 1.596327 \tValidation Loss: 1.811162\n",
            "\tTrain Accuracy: 91.132d% (36453/40000)\tValdation Accuracy: 86.430d% (8643/10000) \n",
            "train epoch[31/50]: 100%|██████████| 313/313 [00:22<00:00, 14.02it/s]\n",
            "valid epoch[31/50]: 100%|██████████| 79/79 [00:04<00:00, 17.12it/s]\n",
            "\tTraining Loss: 1.559872 \tValidation Loss: 1.810961\n",
            "\tTrain Accuracy: 91.403d% (36561/40000)\tValdation Accuracy: 86.500d% (8650/10000) \n",
            "train epoch[32/50]: 100%|██████████| 313/313 [00:23<00:00, 13.48it/s]\n",
            "valid epoch[32/50]: 100%|██████████| 79/79 [00:05<00:00, 14.11it/s]\n",
            "\tTraining Loss: 1.522737 \tValidation Loss: 1.949754\n",
            "\tTrain Accuracy: 91.433d% (36573/40000)\tValdation Accuracy: 85.790d% (8579/10000) \n",
            "train epoch[33/50]: 100%|██████████| 313/313 [00:25<00:00, 12.21it/s]\n",
            "valid epoch[33/50]: 100%|██████████| 79/79 [00:05<00:00, 14.67it/s]\n",
            "\tTraining Loss: 1.527027 \tValidation Loss: 2.038469\n",
            "\tTrain Accuracy: 91.472d% (36589/40000)\tValdation Accuracy: 86.010d% (8601/10000) \n",
            "train epoch[34/50]: 100%|██████████| 313/313 [00:25<00:00, 12.22it/s]\n",
            "valid epoch[34/50]: 100%|██████████| 79/79 [00:05<00:00, 14.67it/s]\n",
            "\tTraining Loss: 1.463375 \tValidation Loss: 2.040192\n",
            "\tTrain Accuracy: 91.820d% (36728/40000)\tValdation Accuracy: 86.430d% (8643/10000) \n",
            "train epoch[35/50]: 100%|██████████| 313/313 [00:25<00:00, 12.43it/s]\n",
            "valid epoch[35/50]: 100%|██████████| 79/79 [00:04<00:00, 17.06it/s]\n",
            "\tTraining Loss: 1.476689 \tValidation Loss: 2.049199\n",
            "\tTrain Accuracy: 91.927d% (36771/40000)\tValdation Accuracy: 85.640d% (8564/10000) \n",
            "train epoch[36/50]: 100%|██████████| 313/313 [00:22<00:00, 14.02it/s]\n",
            "valid epoch[36/50]: 100%|██████████| 79/79 [00:04<00:00, 17.10it/s]\n",
            "\tTraining Loss: 1.507594 \tValidation Loss: 1.851863\n",
            "\tTrain Accuracy: 91.862d% (36745/40000)\tValdation Accuracy: 86.880d% (8688/10000) \n",
            "train epoch[37/50]: 100%|██████████| 313/313 [00:22<00:00, 14.00it/s]\n",
            "valid epoch[37/50]: 100%|██████████| 79/79 [00:04<00:00, 17.08it/s]\n",
            "\tTraining Loss: 1.413301 \tValidation Loss: 1.896778\n",
            "\tTrain Accuracy: 92.138d% (36855/40000)\tValdation Accuracy: 86.370d% (8637/10000) \n",
            "train epoch[38/50]: 100%|██████████| 313/313 [00:22<00:00, 13.99it/s]\n",
            "valid epoch[38/50]: 100%|██████████| 79/79 [00:04<00:00, 16.99it/s]\n",
            "\tTraining Loss: 1.401794 \tValidation Loss: 1.505278\n",
            "\tTrain Accuracy: 92.345d% (36938/40000)\tValdation Accuracy: 86.780d% (8678/10000) \n",
            "train epoch[39/50]: 100%|██████████| 313/313 [00:22<00:00, 14.19it/s]\n",
            "valid epoch[39/50]: 100%|██████████| 79/79 [00:04<00:00, 17.97it/s]\n",
            "\tTraining Loss: 1.406224 \tValidation Loss: 1.607012\n",
            "\tTrain Accuracy: 92.440d% (36976/40000)\tValdation Accuracy: 87.440d% (8744/10000) \n",
            "train epoch[40/50]: 100%|██████████| 313/313 [00:22<00:00, 13.88it/s]\n",
            "valid epoch[40/50]: 100%|██████████| 79/79 [00:04<00:00, 16.58it/s]\n",
            "\tTraining Loss: 1.375638 \tValidation Loss: 1.745990\n",
            "\tTrain Accuracy: 92.485d% (36994/40000)\tValdation Accuracy: 86.930d% (8693/10000) \n",
            "train epoch[41/50]: 100%|██████████| 313/313 [00:21<00:00, 14.28it/s]\n",
            "valid epoch[41/50]: 100%|██████████| 79/79 [00:04<00:00, 17.87it/s]\n",
            "\tTraining Loss: 1.368575 \tValidation Loss: 1.676164\n",
            "\tTrain Accuracy: 92.638d% (37055/40000)\tValdation Accuracy: 86.490d% (8649/10000) \n",
            "train epoch[42/50]: 100%|██████████| 313/313 [00:21<00:00, 14.33it/s]\n",
            "valid epoch[42/50]: 100%|██████████| 79/79 [00:04<00:00, 17.93it/s]\n",
            "\tTraining Loss: 1.356048 \tValidation Loss: 1.684647\n",
            "\tTrain Accuracy: 92.845d% (37138/40000)\tValdation Accuracy: 87.190d% (8719/10000) \n",
            "train epoch[43/50]: 100%|██████████| 313/313 [00:21<00:00, 14.31it/s]\n",
            "valid epoch[43/50]: 100%|██████████| 79/79 [00:04<00:00, 18.03it/s]\n",
            "\tTraining Loss: 1.305893 \tValidation Loss: 1.712529\n",
            "\tTrain Accuracy: 92.722d% (37089/40000)\tValdation Accuracy: 86.680d% (8668/10000) \n",
            "train epoch[44/50]: 100%|██████████| 313/313 [00:21<00:00, 14.29it/s]\n",
            "valid epoch[44/50]: 100%|██████████| 79/79 [00:04<00:00, 18.02it/s]\n",
            "\tTraining Loss: 1.295492 \tValidation Loss: 1.685981\n",
            "\tTrain Accuracy: 92.797d% (37119/40000)\tValdation Accuracy: 86.770d% (8677/10000) \n",
            "train epoch[45/50]: 100%|██████████| 313/313 [00:21<00:00, 14.27it/s]\n",
            "valid epoch[45/50]: 100%|██████████| 79/79 [00:04<00:00, 17.95it/s]\n",
            "\tTraining Loss: 1.313373 \tValidation Loss: 1.509702\n",
            "\tTrain Accuracy: 92.767d% (37107/40000)\tValdation Accuracy: 87.290d% (8729/10000) \n",
            "train epoch[46/50]: 100%|██████████| 313/313 [00:21<00:00, 14.30it/s]\n",
            "valid epoch[46/50]: 100%|██████████| 79/79 [00:04<00:00, 18.06it/s]\n",
            "\tTraining Loss: 1.301111 \tValidation Loss: 1.586094\n",
            "\tTrain Accuracy: 93.120d% (37248/40000)\tValdation Accuracy: 87.600d% (8760/10000) \n",
            "train epoch[47/50]: 100%|██████████| 313/313 [00:21<00:00, 14.38it/s]\n",
            "valid epoch[47/50]: 100%|██████████| 79/79 [00:04<00:00, 18.03it/s]\n",
            "\tTraining Loss: 1.309918 \tValidation Loss: 1.762139\n",
            "\tTrain Accuracy: 93.165d% (37266/40000)\tValdation Accuracy: 87.500d% (8750/10000) \n",
            "train epoch[48/50]: 100%|██████████| 313/313 [00:21<00:00, 14.35it/s]\n",
            "valid epoch[48/50]: 100%|██████████| 79/79 [00:04<00:00, 17.86it/s]\n",
            "\tTraining Loss: 1.252992 \tValidation Loss: 1.705543\n",
            "\tTrain Accuracy: 93.390d% (37356/40000)\tValdation Accuracy: 87.060d% (8706/10000) \n",
            "train epoch[49/50]: 100%|██████████| 313/313 [00:21<00:00, 14.28it/s]\n",
            "valid epoch[49/50]: 100%|██████████| 79/79 [00:04<00:00, 17.90it/s]\n",
            "\tTraining Loss: 1.228128 \tValidation Loss: 1.671651\n",
            "\tTrain Accuracy: 93.257d% (37303/40000)\tValdation Accuracy: 87.720d% (8772/10000) \n",
            "train epoch[50/50]: 100%|██████████| 313/313 [00:22<00:00, 14.20it/s]\n",
            "valid epoch[50/50]: 100%|██████████| 79/79 [00:04<00:00, 17.17it/s]\n",
            "\tTraining Loss: 1.250469 \tValidation Loss: 1.569499\n",
            "\tTrain Accuracy: 93.132d% (37253/40000)\tValdation Accuracy: 87.380d% (8738/10000) \n",
            "Finished Distilling\n"
          ]
        }
      ],
      "source": [
        "# Decide the epochs and learning rate\n",
        "Student_re = resnet18(num_classes=10)\n",
        "Student_re = Student_re.to(device)\n",
        "distiller_re = Distiller(Teacher, Student_re, type='response')\n",
        "train_distillation(distiller_re, Student_re, train_loader, val_loader, epochs= 50, learning_rate= 0.001, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T17:46:23.908450Z",
          "iopub.status.busy": "2025-09-15T17:46:23.908252Z",
          "iopub.status.idle": "2025-09-15T17:46:37.767639Z",
          "shell.execute_reply": "2025-09-15T17:46:37.767023Z",
          "shell.execute_reply.started": "2025-09-15T17:46:23.908424Z"
        },
        "id": "uSwU5ooswdUO",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test: 100%|██████████| 79/79 [00:03<00:00, 26.02it/s]\n",
            "test_loss: 1.832  test_accuracy: 88.580\n"
          ]
        }
      ],
      "source": [
        "reS_loss, reS_accuracy = test(distiller_re, test_loader, type='distiller', device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdisKpMOwdUP"
      },
      "source": [
        "## Feature-based distillation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpshhQrNwdUP",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train epoch[1/50]: 100%|██████████| 313/313 [00:25<00:00, 12.34it/s]\n",
            "valid epoch[1/50]:  23%|██▎       | 18/79 [00:01<00:04, 14.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid epoch[1/50]: 100%|██████████| 79/79 [00:05<00:00, 14.92it/s]\n",
            "\tTraining Loss: 0.931146 \tValidation Loss: 0.880209\n",
            "\tTrain Accuracy: 30.977d% (12391/40000)\tValdation Accuracy: 38.210d% (3821/10000) \n",
            "train epoch[2/50]: 100%|██████████| 313/313 [00:24<00:00, 12.75it/s]\n",
            "valid epoch[2/50]: 100%|██████████| 79/79 [00:05<00:00, 14.89it/s]\n",
            "\tTraining Loss: 0.682901 \tValidation Loss: 0.689893\n",
            "\tTrain Accuracy: 49.852d% (19941/40000)\tValdation Accuracy: 51.160d% (5116/10000) \n",
            "train epoch[3/50]: 100%|██████████| 313/313 [00:24<00:00, 12.74it/s]\n",
            "valid epoch[3/50]: 100%|██████████| 79/79 [00:05<00:00, 14.83it/s]\n",
            "\tTraining Loss: 0.569812 \tValidation Loss: 0.653412\n",
            "\tTrain Accuracy: 59.538d% (23815/40000)\tValdation Accuracy: 55.340d% (5534/10000) \n",
            "train epoch[4/50]: 100%|██████████| 313/313 [00:24<00:00, 12.84it/s]\n",
            "valid epoch[4/50]: 100%|██████████| 79/79 [00:05<00:00, 14.76it/s]\n",
            "\tTraining Loss: 0.496760 \tValidation Loss: 0.519901\n",
            "\tTrain Accuracy: 65.170d% (26068/40000)\tValdation Accuracy: 63.480d% (6348/10000) \n",
            "train epoch[5/50]: 100%|██████████| 313/313 [00:24<00:00, 12.65it/s]\n",
            "valid epoch[5/50]: 100%|██████████| 79/79 [00:05<00:00, 14.86it/s]\n",
            "\tTraining Loss: 0.446526 \tValidation Loss: 0.482012\n",
            "\tTrain Accuracy: 68.755d% (27502/40000)\tValdation Accuracy: 66.250d% (6625/10000) \n",
            "train epoch[6/50]: 100%|██████████| 313/313 [00:24<00:00, 12.73it/s]\n",
            "valid epoch[6/50]: 100%|██████████| 79/79 [00:05<00:00, 15.03it/s]\n",
            "\tTraining Loss: 0.400092 \tValidation Loss: 0.456613\n",
            "\tTrain Accuracy: 72.108d% (28843/40000)\tValdation Accuracy: 68.220d% (6822/10000) \n",
            "train epoch[7/50]: 100%|██████████| 313/313 [00:24<00:00, 12.74it/s]\n",
            "valid epoch[7/50]: 100%|██████████| 79/79 [00:05<00:00, 15.05it/s]\n",
            "\tTraining Loss: 0.358820 \tValidation Loss: 0.433333\n",
            "\tTrain Accuracy: 75.110d% (30044/40000)\tValdation Accuracy: 70.480d% (7048/10000) \n",
            "train epoch[8/50]: 100%|██████████| 313/313 [00:24<00:00, 12.70it/s]\n",
            "valid epoch[8/50]: 100%|██████████| 79/79 [00:05<00:00, 14.93it/s]\n",
            "\tTraining Loss: 0.325266 \tValidation Loss: 0.360328\n",
            "\tTrain Accuracy: 77.573d% (31029/40000)\tValdation Accuracy: 75.590d% (7559/10000) \n",
            "train epoch[9/50]: 100%|██████████| 313/313 [00:24<00:00, 12.65it/s]\n",
            "valid epoch[9/50]: 100%|██████████| 79/79 [00:05<00:00, 15.01it/s]\n",
            "\tTraining Loss: 0.300960 \tValidation Loss: 0.359203\n",
            "\tTrain Accuracy: 79.203d% (31681/40000)\tValdation Accuracy: 75.340d% (7534/10000) \n",
            "train epoch[10/50]: 100%|██████████| 313/313 [00:24<00:00, 12.64it/s]\n",
            "valid epoch[10/50]: 100%|██████████| 79/79 [00:05<00:00, 15.10it/s]\n",
            "\tTraining Loss: 0.276586 \tValidation Loss: 0.341742\n",
            "\tTrain Accuracy: 80.987d% (32395/40000)\tValdation Accuracy: 76.570d% (7657/10000) \n",
            "train epoch[11/50]: 100%|██████████| 313/313 [00:24<00:00, 12.64it/s]\n",
            "valid epoch[11/50]: 100%|██████████| 79/79 [00:05<00:00, 15.18it/s]\n",
            "\tTraining Loss: 0.257404 \tValidation Loss: 0.378238\n",
            "\tTrain Accuracy: 82.155d% (32862/40000)\tValdation Accuracy: 75.950d% (7595/10000) \n",
            "train epoch[12/50]: 100%|██████████| 313/313 [00:24<00:00, 12.67it/s]\n",
            "valid epoch[12/50]: 100%|██████████| 79/79 [00:04<00:00, 18.49it/s]\n",
            "\tTraining Loss: 0.240432 \tValidation Loss: 0.316143\n",
            "\tTrain Accuracy: 83.630d% (33452/40000)\tValdation Accuracy: 79.030d% (7903/10000) \n",
            "train epoch[13/50]: 100%|██████████| 313/313 [00:22<00:00, 13.64it/s]\n",
            "valid epoch[13/50]: 100%|██████████| 79/79 [00:04<00:00, 18.55it/s]\n",
            "\tTraining Loss: 0.226503 \tValidation Loss: 0.278034\n",
            "\tTrain Accuracy: 84.260d% (33704/40000)\tValdation Accuracy: 81.560d% (8156/10000) \n",
            "train epoch[14/50]: 100%|██████████| 313/313 [00:23<00:00, 13.07it/s]\n",
            "valid epoch[14/50]: 100%|██████████| 79/79 [00:05<00:00, 15.12it/s]\n",
            "\tTraining Loss: 0.213749 \tValidation Loss: 0.306116\n",
            "\tTrain Accuracy: 85.395d% (34158/40000)\tValdation Accuracy: 80.200d% (8020/10000) \n",
            "train epoch[15/50]: 100%|██████████| 313/313 [00:24<00:00, 12.96it/s]\n",
            "valid epoch[15/50]: 100%|██████████| 79/79 [00:04<00:00, 16.00it/s]\n",
            "\tTraining Loss: 0.202075 \tValidation Loss: 0.286294\n",
            "\tTrain Accuracy: 85.933d% (34373/40000)\tValdation Accuracy: 80.880d% (8088/10000) \n",
            "train epoch[16/50]: 100%|██████████| 313/313 [00:23<00:00, 13.17it/s]\n",
            "valid epoch[16/50]: 100%|██████████| 79/79 [00:04<00:00, 16.06it/s]\n",
            "\tTraining Loss: 0.193205 \tValidation Loss: 0.268184\n",
            "\tTrain Accuracy: 86.770d% (34708/40000)\tValdation Accuracy: 82.520d% (8252/10000) \n",
            "train epoch[17/50]: 100%|██████████| 313/313 [00:23<00:00, 13.57it/s]\n",
            "valid epoch[17/50]: 100%|██████████| 79/79 [00:04<00:00, 18.55it/s]\n",
            "\tTraining Loss: 0.186434 \tValidation Loss: 0.276535\n",
            "\tTrain Accuracy: 87.105d% (34842/40000)\tValdation Accuracy: 81.870d% (8187/10000) \n",
            "train epoch[18/50]: 100%|██████████| 313/313 [00:24<00:00, 12.78it/s]\n",
            "valid epoch[18/50]: 100%|██████████| 79/79 [00:05<00:00, 14.83it/s]\n",
            "\tTraining Loss: 0.172127 \tValidation Loss: 0.258132\n",
            "\tTrain Accuracy: 88.118d% (35247/40000)\tValdation Accuracy: 82.900d% (8290/10000) \n",
            "train epoch[19/50]: 100%|██████████| 313/313 [00:25<00:00, 12.35it/s]\n",
            "valid epoch[19/50]: 100%|██████████| 79/79 [00:05<00:00, 15.39it/s]\n",
            "\tTraining Loss: 0.168607 \tValidation Loss: 0.262555\n",
            "\tTrain Accuracy: 88.468d% (35387/40000)\tValdation Accuracy: 83.230d% (8323/10000) \n",
            "train epoch[20/50]: 100%|██████████| 313/313 [00:24<00:00, 12.85it/s]\n",
            "valid epoch[20/50]: 100%|██████████| 79/79 [00:05<00:00, 15.64it/s]\n",
            "\tTraining Loss: 0.163429 \tValidation Loss: 0.251804\n",
            "\tTrain Accuracy: 88.912d% (35565/40000)\tValdation Accuracy: 83.650d% (8365/10000) \n",
            "train epoch[21/50]: 100%|██████████| 313/313 [00:24<00:00, 12.87it/s]\n",
            "valid epoch[21/50]: 100%|██████████| 79/79 [00:05<00:00, 15.71it/s]\n",
            "\tTraining Loss: 0.152985 \tValidation Loss: 0.251450\n",
            "\tTrain Accuracy: 89.502d% (35801/40000)\tValdation Accuracy: 83.310d% (8331/10000) \n",
            "train epoch[22/50]: 100%|██████████| 313/313 [00:24<00:00, 12.76it/s]\n",
            "valid epoch[22/50]: 100%|██████████| 79/79 [00:04<00:00, 18.35it/s]\n",
            "\tTraining Loss: 0.147359 \tValidation Loss: 0.277524\n",
            "\tTrain Accuracy: 90.035d% (36014/40000)\tValdation Accuracy: 82.900d% (8290/10000) \n",
            "train epoch[23/50]: 100%|██████████| 313/313 [00:24<00:00, 12.65it/s]\n",
            "valid epoch[23/50]: 100%|██████████| 79/79 [00:04<00:00, 18.47it/s]\n",
            "\tTraining Loss: 0.141997 \tValidation Loss: 0.243507\n",
            "\tTrain Accuracy: 90.218d% (36087/40000)\tValdation Accuracy: 84.610d% (8461/10000) \n",
            "train epoch[24/50]: 100%|██████████| 313/313 [00:24<00:00, 12.66it/s]\n",
            "valid epoch[24/50]: 100%|██████████| 79/79 [00:04<00:00, 18.46it/s]\n",
            "\tTraining Loss: 0.138078 \tValidation Loss: 0.242661\n",
            "\tTrain Accuracy: 90.545d% (36218/40000)\tValdation Accuracy: 84.500d% (8450/10000) \n",
            "train epoch[25/50]: 100%|██████████| 313/313 [00:23<00:00, 13.28it/s]\n",
            "valid epoch[25/50]: 100%|██████████| 79/79 [00:04<00:00, 18.42it/s]\n",
            "\tTraining Loss: 0.128809 \tValidation Loss: 0.235808\n",
            "\tTrain Accuracy: 91.230d% (36492/40000)\tValdation Accuracy: 84.860d% (8486/10000) \n",
            "train epoch[26/50]: 100%|██████████| 313/313 [00:23<00:00, 13.56it/s]\n",
            "valid epoch[26/50]: 100%|██████████| 79/79 [00:04<00:00, 18.47it/s]\n",
            "\tTraining Loss: 0.123753 \tValidation Loss: 0.254108\n",
            "\tTrain Accuracy: 91.483d% (36593/40000)\tValdation Accuracy: 84.410d% (8441/10000) \n",
            "train epoch[27/50]: 100%|██████████| 313/313 [00:23<00:00, 13.55it/s]\n",
            "valid epoch[27/50]: 100%|██████████| 79/79 [00:04<00:00, 18.45it/s]\n",
            "\tTraining Loss: 0.120077 \tValidation Loss: 0.228315\n",
            "\tTrain Accuracy: 91.823d% (36729/40000)\tValdation Accuracy: 85.100d% (8510/10000) \n",
            "train epoch[28/50]: 100%|██████████| 313/313 [00:23<00:00, 13.55it/s]\n",
            "valid epoch[28/50]: 100%|██████████| 79/79 [00:04<00:00, 18.44it/s]\n",
            "\tTraining Loss: 0.115072 \tValidation Loss: 0.252507\n",
            "\tTrain Accuracy: 92.075d% (36830/40000)\tValdation Accuracy: 84.700d% (8470/10000) \n",
            "train epoch[29/50]: 100%|██████████| 313/313 [00:23<00:00, 13.54it/s]\n",
            "valid epoch[29/50]: 100%|██████████| 79/79 [00:04<00:00, 18.40it/s]\n",
            "\tTraining Loss: 0.112499 \tValidation Loss: 0.250781\n",
            "\tTrain Accuracy: 92.280d% (36912/40000)\tValdation Accuracy: 84.870d% (8487/10000) \n",
            "train epoch[30/50]: 100%|██████████| 313/313 [00:23<00:00, 13.53it/s]\n",
            "valid epoch[30/50]: 100%|██████████| 79/79 [00:04<00:00, 18.39it/s]\n",
            "\tTraining Loss: 0.103012 \tValidation Loss: 0.257906\n",
            "\tTrain Accuracy: 92.983d% (37193/40000)\tValdation Accuracy: 84.860d% (8486/10000) \n",
            "train epoch[31/50]: 100%|██████████| 313/313 [00:23<00:00, 13.53it/s]\n",
            "valid epoch[31/50]: 100%|██████████| 79/79 [00:04<00:00, 18.36it/s]\n",
            "\tTraining Loss: 0.103003 \tValidation Loss: 0.241521\n",
            "\tTrain Accuracy: 92.965d% (37186/40000)\tValdation Accuracy: 85.070d% (8507/10000) \n",
            "train epoch[32/50]: 100%|██████████| 313/313 [00:23<00:00, 13.55it/s]\n",
            "valid epoch[32/50]: 100%|██████████| 79/79 [00:04<00:00, 18.42it/s]\n",
            "\tTraining Loss: 0.100419 \tValidation Loss: 0.242517\n",
            "\tTrain Accuracy: 93.013d% (37205/40000)\tValdation Accuracy: 85.490d% (8549/10000) \n",
            "train epoch[33/50]: 100%|██████████| 313/313 [00:23<00:00, 13.56it/s]\n",
            "valid epoch[33/50]: 100%|██████████| 79/79 [00:04<00:00, 18.50it/s]\n",
            "\tTraining Loss: 0.097272 \tValidation Loss: 0.234499\n",
            "\tTrain Accuracy: 93.308d% (37323/40000)\tValdation Accuracy: 85.770d% (8577/10000) \n",
            "train epoch[34/50]: 100%|██████████| 313/313 [00:23<00:00, 13.58it/s]\n",
            "valid epoch[34/50]: 100%|██████████| 79/79 [00:04<00:00, 18.48it/s]\n",
            "\tTraining Loss: 0.089564 \tValidation Loss: 0.244024\n",
            "\tTrain Accuracy: 93.897d% (37559/40000)\tValdation Accuracy: 85.880d% (8588/10000) \n",
            "train epoch[35/50]: 100%|██████████| 313/313 [00:23<00:00, 13.59it/s]\n",
            "valid epoch[35/50]: 100%|██████████| 79/79 [00:04<00:00, 18.48it/s]\n",
            "\tTraining Loss: 0.092637 \tValidation Loss: 0.268148\n",
            "\tTrain Accuracy: 93.675d% (37470/40000)\tValdation Accuracy: 84.910d% (8491/10000) \n",
            "train epoch[36/50]: 100%|██████████| 313/313 [00:23<00:00, 13.55it/s]\n",
            "valid epoch[36/50]: 100%|██████████| 79/79 [00:04<00:00, 18.48it/s]\n",
            "\tTraining Loss: 0.088235 \tValidation Loss: 0.260999\n",
            "\tTrain Accuracy: 94.045d% (37618/40000)\tValdation Accuracy: 85.190d% (8519/10000) \n",
            "train epoch[37/50]: 100%|██████████| 313/313 [00:23<00:00, 13.57it/s]\n",
            "valid epoch[37/50]: 100%|██████████| 79/79 [00:04<00:00, 18.50it/s]\n",
            "\tTraining Loss: 0.084809 \tValidation Loss: 0.250641\n",
            "\tTrain Accuracy: 94.185d% (37674/40000)\tValdation Accuracy: 86.010d% (8601/10000) \n",
            "train epoch[38/50]: 100%|██████████| 313/313 [00:23<00:00, 13.58it/s]\n",
            "valid epoch[38/50]: 100%|██████████| 79/79 [00:04<00:00, 18.51it/s]\n",
            "\tTraining Loss: 0.080895 \tValidation Loss: 0.260270\n",
            "\tTrain Accuracy: 94.475d% (37790/40000)\tValdation Accuracy: 85.020d% (8502/10000) \n",
            "train epoch[39/50]: 100%|██████████| 313/313 [00:23<00:00, 13.58it/s]\n",
            "valid epoch[39/50]: 100%|██████████| 79/79 [00:04<00:00, 18.54it/s]\n",
            "\tTraining Loss: 0.078929 \tValidation Loss: 0.266634\n",
            "\tTrain Accuracy: 94.698d% (37879/40000)\tValdation Accuracy: 84.680d% (8468/10000) \n",
            "train epoch[40/50]: 100%|██████████| 313/313 [00:23<00:00, 13.59it/s]\n",
            "valid epoch[40/50]: 100%|██████████| 79/79 [00:04<00:00, 18.50it/s]\n",
            "\tTraining Loss: 0.072705 \tValidation Loss: 0.250615\n",
            "\tTrain Accuracy: 95.000d% (38000/40000)\tValdation Accuracy: 86.300d% (8630/10000) \n",
            "train epoch[41/50]: 100%|██████████| 313/313 [00:23<00:00, 13.60it/s]\n",
            "valid epoch[41/50]: 100%|██████████| 79/79 [00:04<00:00, 18.51it/s]\n",
            "\tTraining Loss: 0.074805 \tValidation Loss: 0.266543\n",
            "\tTrain Accuracy: 94.960d% (37984/40000)\tValdation Accuracy: 85.140d% (8514/10000) \n",
            "train epoch[42/50]: 100%|██████████| 313/313 [00:23<00:00, 13.58it/s]\n",
            "valid epoch[42/50]: 100%|██████████| 79/79 [00:04<00:00, 18.51it/s]\n",
            "\tTraining Loss: 0.076088 \tValidation Loss: 0.240643\n",
            "\tTrain Accuracy: 94.830d% (37932/40000)\tValdation Accuracy: 86.380d% (8638/10000) \n",
            "train epoch[43/50]: 100%|██████████| 313/313 [00:23<00:00, 13.59it/s]\n",
            "valid epoch[43/50]: 100%|██████████| 79/79 [00:04<00:00, 18.51it/s]\n",
            "\tTraining Loss: 0.070516 \tValidation Loss: 0.248878\n",
            "\tTrain Accuracy: 95.055d% (38022/40000)\tValdation Accuracy: 86.740d% (8674/10000) \n",
            "train epoch[44/50]: 100%|██████████| 313/313 [00:23<00:00, 13.58it/s]\n",
            "valid epoch[44/50]: 100%|██████████| 79/79 [00:04<00:00, 18.51it/s]\n",
            "\tTraining Loss: 0.068670 \tValidation Loss: 0.256318\n",
            "\tTrain Accuracy: 95.260d% (38104/40000)\tValdation Accuracy: 86.360d% (8636/10000) \n",
            "train epoch[45/50]: 100%|██████████| 313/313 [00:23<00:00, 13.60it/s]\n",
            "valid epoch[45/50]: 100%|██████████| 79/79 [00:04<00:00, 18.52it/s]\n",
            "\tTraining Loss: 0.064390 \tValidation Loss: 0.273949\n",
            "\tTrain Accuracy: 95.567d% (38227/40000)\tValdation Accuracy: 85.610d% (8561/10000) \n",
            "train epoch[46/50]: 100%|██████████| 313/313 [00:23<00:00, 13.59it/s]\n",
            "valid epoch[46/50]: 100%|██████████| 79/79 [00:04<00:00, 18.51it/s]\n",
            "\tTraining Loss: 0.064819 \tValidation Loss: 0.254511\n",
            "\tTrain Accuracy: 95.558d% (38223/40000)\tValdation Accuracy: 85.830d% (8583/10000) \n",
            "train epoch[47/50]: 100%|██████████| 313/313 [00:23<00:00, 13.56it/s]\n",
            "valid epoch[47/50]: 100%|██████████| 79/79 [00:04<00:00, 18.48it/s]\n",
            "\tTraining Loss: 0.061192 \tValidation Loss: 0.262040\n",
            "\tTrain Accuracy: 95.828d% (38331/40000)\tValdation Accuracy: 86.110d% (8611/10000) \n",
            "train epoch[48/50]: 100%|██████████| 313/313 [00:23<00:00, 13.55it/s]\n",
            "valid epoch[48/50]: 100%|██████████| 79/79 [00:04<00:00, 18.43it/s]\n",
            "\tTraining Loss: 0.063114 \tValidation Loss: 0.265088\n",
            "\tTrain Accuracy: 95.690d% (38276/40000)\tValdation Accuracy: 85.920d% (8592/10000) \n",
            "train epoch[49/50]: 100%|██████████| 313/313 [00:23<00:00, 13.56it/s]\n",
            "valid epoch[49/50]: 100%|██████████| 79/79 [00:04<00:00, 18.48it/s]\n",
            "\tTraining Loss: 0.058905 \tValidation Loss: 0.278999\n",
            "\tTrain Accuracy: 96.022d% (38409/40000)\tValdation Accuracy: 85.550d% (8555/10000) \n",
            "train epoch[50/50]: 100%|██████████| 313/313 [00:23<00:00, 13.56it/s]\n",
            "valid epoch[50/50]: 100%|██████████| 79/79 [00:04<00:00, 18.46it/s]\n",
            "\tTraining Loss: 0.057317 \tValidation Loss: 0.252650\n",
            "\tTrain Accuracy: 96.043d% (38417/40000)\tValdation Accuracy: 86.730d% (8673/10000) \n",
            "Finished Distilling\n"
          ]
        }
      ],
      "source": [
        "# Decide the epochs and learning rate\n",
        "Student_fe = resnet18(num_classes=10)\n",
        "Student_fe = Student_fe.to(device)\n",
        "distiller_fe = Distiller(Teacher, Student_fe, type='feature')\n",
        "train_distillation(distiller_fe, Student_fe, train_loader, val_loader, epochs= 50, learning_rate=0.001 , device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T18:12:41.350107Z",
          "iopub.status.busy": "2025-09-15T18:12:41.349535Z",
          "iopub.status.idle": "2025-09-15T18:12:56.380748Z",
          "shell.execute_reply": "2025-09-15T18:12:56.380147Z",
          "shell.execute_reply.started": "2025-09-15T18:12:41.350082Z"
        },
        "id": "zM9-xs6SwdUP",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test: 100%|██████████| 79/79 [00:04<00:00, 17.61it/s]\n",
            "test_loss: 0.249  test_accuracy: 87.690\n"
          ]
        }
      ],
      "source": [
        "ftS_loss, ftS_accuracy = test(distiller_fe, test_loader, type='distiller', device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4X7OsAvhwdUP"
      },
      "source": [
        "## Result and Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-15T18:12:56.382324Z",
          "iopub.status.busy": "2025-09-15T18:12:56.381931Z",
          "iopub.status.idle": "2025-09-15T18:12:56.387139Z",
          "shell.execute_reply": "2025-09-15T18:12:56.386278Z",
          "shell.execute_reply.started": "2025-09-15T18:12:56.382306Z"
        },
        "id": "nsK1wsDmwdUP",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher from scratch: loss = 0.43, accuracy = 89.26\n",
            "Student from scratch: loss = 0.57, accuracy = 87.89\n",
            "Response-based student: loss = 1.83, accuracy = 88.58\n",
            "Featured-based student: loss = 0.25, accuracy = 87.69\n"
          ]
        }
      ],
      "source": [
        "print(f'Teacher from scratch: loss = {T_loss:.2f}, accuracy = {T_accuracy:.2f}')\n",
        "print(f'Student from scratch: loss = {S_loss:.2f}, accuracy = {S_accuracy:.2f}')\n",
        "print(f'Response-based student: loss = {reS_loss:.2f}, accuracy = {reS_accuracy:.2f}')\n",
        "print(f'Featured-based student: loss = {ftS_loss:.2f}, accuracy = {ftS_accuracy:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "isSourceIdPinned": true,
          "modelId": 450656,
          "modelInstanceId": 433802,
          "sourceId": 581181,
          "sourceType": "modelInstanceVersion"
        }
      ],
      "dockerImageVersionId": 31090,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
